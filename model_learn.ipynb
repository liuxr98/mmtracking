{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2280f9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.7.1-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.7.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12da0f5b-abe7-4f31-9737-668f2babee8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error importing BURST due to missing underlying dependency: No module named 'tabulate'\n",
      "Config:\n",
      "dataset_type = 'CocoDataset'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile', to_float32=True, color_type='color'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        type='PhotoMetricDistortion',\n",
      "        brightness_delta=32,\n",
      "        contrast_range=(0.5, 1.5),\n",
      "        saturation_range=(0.5, 1.5),\n",
      "        hue_delta=18),\n",
      "    dict(\n",
      "        type='RandomCenterCropPad',\n",
      "        crop_size=(512, 512),\n",
      "        ratios=(0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3),\n",
      "        mean=[0, 0, 0],\n",
      "        std=[1, 1, 1],\n",
      "        to_rgb=True,\n",
      "        test_pad_mode=None),\n",
      "    dict(type='Resize', img_scale=(512, 512), keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile', to_float32=True),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        scale_factor=1.0,\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(\n",
      "                type='RandomCenterCropPad',\n",
      "                ratios=None,\n",
      "                border=None,\n",
      "                mean=[0, 0, 0],\n",
      "                std=[1, 1, 1],\n",
      "                to_rgb=True,\n",
      "                test_mode=True,\n",
      "                test_pad_mode=['logical_or', 31],\n",
      "                test_pad_add_pix=1),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(\n",
      "                type='Collect',\n",
      "                meta_keys=('filename', 'ori_filename', 'ori_shape',\n",
      "                           'img_shape', 'pad_shape', 'scale_factor', 'flip',\n",
      "                           'flip_direction', 'img_norm_cfg', 'border'),\n",
      "                keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data_root = 'data/VisDrone_MOT/'\n",
      "data = dict(\n",
      "    samples_per_gpu=16,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/VisDrone_MOT/train/cocoformat.json',\n",
      "        img_prefix='data/VisDrone_MOT/train/',\n",
      "        classes=('pedestrian', 'people', 'bicycle', 'car', 'van', 'truck',\n",
      "                 'tricycle', 'awning-tricycle', 'bus', 'motor'),\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='LoadImageFromFile', to_float32=True, color_type='color'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                type='PhotoMetricDistortion',\n",
      "                brightness_delta=32,\n",
      "                contrast_range=(0.5, 1.5),\n",
      "                saturation_range=(0.5, 1.5),\n",
      "                hue_delta=18),\n",
      "            dict(\n",
      "                type='RandomCenterCropPad',\n",
      "                crop_size=(512, 512),\n",
      "                ratios=(0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3),\n",
      "                mean=[0, 0, 0],\n",
      "                std=[1, 1, 1],\n",
      "                to_rgb=True,\n",
      "                test_pad_mode=None),\n",
      "            dict(type='Resize', img_scale=(512, 512), keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/VisDrone_MOT/test/cocoformat.json',\n",
      "        img_prefix='data/VisDrone_MOT/test/',\n",
      "        classes=('pedestrian', 'people', 'bicycle', 'car', 'van', 'truck',\n",
      "                 'tricycle', 'awning-tricycle', 'bus', 'motor'),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile', to_float32=True),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                scale_factor=1.0,\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(\n",
      "                        type='RandomCenterCropPad',\n",
      "                        ratios=None,\n",
      "                        border=None,\n",
      "                        mean=[0, 0, 0],\n",
      "                        std=[1, 1, 1],\n",
      "                        to_rgb=True,\n",
      "                        test_mode=True,\n",
      "                        test_pad_mode=['logical_or', 31],\n",
      "                        test_pad_add_pix=1),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='DefaultFormatBundle'),\n",
      "                    dict(\n",
      "                        type='Collect',\n",
      "                        meta_keys=('filename', 'ori_filename', 'ori_shape',\n",
      "                                   'img_shape', 'pad_shape', 'scale_factor',\n",
      "                                   'flip', 'flip_direction', 'img_norm_cfg',\n",
      "                                   'border'),\n",
      "                        keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/VisDrone_MOT/test/cocoformat.json',\n",
      "        img_prefix='data/VisDrone_MOT/test/',\n",
      "        classes=('pedestrian', 'people', 'bicycle', 'car', 'van', 'truck',\n",
      "                 'tricycle', 'awning-tricycle', 'bus', 'motor'),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile', to_float32=True),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                scale_factor=1.0,\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(\n",
      "                        type='RandomCenterCropPad',\n",
      "                        ratios=None,\n",
      "                        border=None,\n",
      "                        mean=[0, 0, 0],\n",
      "                        std=[1, 1, 1],\n",
      "                        to_rgb=True,\n",
      "                        test_mode=True,\n",
      "                        test_pad_mode=['logical_or', 31],\n",
      "                        test_pad_add_pix=1),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='DefaultFormatBundle'),\n",
      "                    dict(\n",
      "                        type='Collect',\n",
      "                        meta_keys=('filename', 'ori_filename', 'ori_shape',\n",
      "                                   'img_shape', 'pad_shape', 'scale_factor',\n",
      "                                   'flip', 'flip_direction', 'img_norm_cfg',\n",
      "                                   'border'),\n",
      "                        keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "evaluation = dict(metric=['bbox'])\n",
      "optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "USE_MMDET = True\n",
      "model = dict(\n",
      "    detector=dict(\n",
      "        type='CenterNet',\n",
      "        backbone=dict(\n",
      "            type='ResNet',\n",
      "            depth=18,\n",
      "            norm_eval=False,\n",
      "            norm_cfg=dict(type='BN'),\n",
      "            init_cfg=dict(\n",
      "                type='Pretrained', checkpoint='torchvision://resnet18')),\n",
      "        neck=dict(\n",
      "            type='CTResNetNeck',\n",
      "            in_channel=512,\n",
      "            num_deconv_filters=(256, 128, 64),\n",
      "            num_deconv_kernels=(4, 4, 4),\n",
      "            use_dcn=True),\n",
      "        bbox_head=dict(\n",
      "            type='CenterNetHead',\n",
      "            num_classes=10,\n",
      "            in_channel=64,\n",
      "            feat_channel=64,\n",
      "            loss_center_heatmap=dict(\n",
      "                type='GaussianFocalLoss', loss_weight=1.0),\n",
      "            loss_wh=dict(type='L1Loss', loss_weight=0.1),\n",
      "            loss_offset=dict(type='L1Loss', loss_weight=1.0)),\n",
      "        train_cfg=None,\n",
      "        test_cfg=dict(topk=100, local_maximum_kernel=3, max_per_img=100)))\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=1000,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[18, 24])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=28)\n",
      "auto_scale_lr = dict(base_batch_size=16)\n",
      "seed = 0\n",
      "work_dir = './tutorial_exps/detector/centernet'\n",
      "device = 'cuda'\n",
      "gpu_ids = [0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "from mmdet.apis import set_random_seed\n",
    "import os.path as osp\n",
    "\n",
    "from mmtrack.datasets import build_dataset\n",
    "from mmdet.apis import train_detector as train_model\n",
    "from mmdet.models import build_detector as build_model\n",
    "\n",
    "# configs\n",
    "cfg = mmcv.Config.fromfile('./configs/det/centernet_visdrone.py')\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "\n",
    "## work_dir\n",
    "cfg.work_dir = './tutorial_exps/detector/centernet'\n",
    "\n",
    "## GPu\n",
    "cfg.device = \"cuda\"\n",
    "cfg.gpu_ids = [0] # cfg.gpu_ids = range(1)\n",
    "\n",
    "## dataset config\n",
    "cfg.data.train.classes = ('pedestrian', 'people', 'bicycle', 'car', 'van', 'truck', 'tricycle', 'awning-tricycle', 'bus', 'motor')\n",
    "cfg.data.val.classes = ('pedestrian', 'people', 'bicycle', 'car', 'van', 'truck', 'tricycle', 'awning-tricycle', 'bus', 'motor')\n",
    "cfg.data.test.classes = ('pedestrian', 'people', 'bicycle', 'car', 'van', 'truck', 'tricycle', 'awning-tricycle', 'bus', 'motor')\n",
    "\n",
    "## model config\n",
    "cfg.model.detector.bbox_head.num_classes = 10\n",
    "\n",
    "# optimizer\n",
    "# Based on the default settings of modern detectors, the SGD effect is better\n",
    "# than the Adam in the source code, so we use SGD default settings and\n",
    "# if you use adam+lr5e-4, the map is 29.1.\n",
    "# cfg.optimizer_config = dict(\n",
    "#     _delete_=True, grad_clip=dict(max_norm=35, norm_type=2))\n",
    "cfg.optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
    "\n",
    "# learning policy\n",
    "# Based on the default settings of modern detectors, we added warmup settings.\n",
    "cfg.lr_config = dict(\n",
    "    policy='step',\n",
    "    warmup='linear',\n",
    "    warmup_iters=1000,\n",
    "    warmup_ratio=1.0 / 1000,\n",
    "    step=[18, 24])  # the real step is [18*5, 24*5]\n",
    "\n",
    "# epoch\n",
    "cfg.runner = dict(type='EpochBasedRunner', max_epochs=28)\n",
    "\n",
    "print(f'Config:\\n{cfg.pretty_text}')\n",
    "\n",
    "# run and test\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "model = build_model(cfg.model.detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8adec618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CenterNet(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): ResLayer(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): ResLayer(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): ResLayer(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): ResLayer(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Pretrained', 'checkpoint': 'torchvision://resnet18'}\n",
       "  (neck): CTResNetNeck(\n",
       "    (deconv_layers): Sequential(\n",
       "      (0): ConvModule(\n",
       "        (conv): ModulatedDeformConv2dPack(\n",
       "          (conv_offset): Conv2d(512, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): ModulatedDeformConv2dPack(\n",
       "          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): ConvModule(\n",
       "        (conv): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): ConvModule(\n",
       "        (conv): ModulatedDeformConv2dPack(\n",
       "          (conv_offset): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): ConvModule(\n",
       "        (conv): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bbox_head): CenterNetHead(\n",
       "    (heatmap_head): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (wh_head): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (offset_head): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (loss_center_heatmap): GaussianFocalLoss()\n",
       "    (loss_wh): L1Loss()\n",
       "    (loss_offset): L1Loss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c926dab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
