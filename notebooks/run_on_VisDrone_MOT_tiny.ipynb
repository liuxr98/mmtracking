{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检测器模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集处理（转化为CocoVID格式）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm ./data/VisDrone_MOT_tiny/train/cocoformat.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 24.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# convert the dataset to coco format\n",
    "!python ./tools/convert_datasets/visdronemot/visdronemot2coco.py -d ./data/VisDrone_MOT_tiny/train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm ./data/VisDrone_MOT_tiny/test/cocoformat.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 26.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# convert the dataset to coco format\n",
    "!python ./tools/convert_datasets/visdronemot/visdronemot2coco.py -d ./data/VisDrone_MOT_tiny/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 修改训练配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    detector=dict(\n",
      "        type='FasterRCNN',\n",
      "        backbone=dict(\n",
      "            type='ResNet',\n",
      "            depth=50,\n",
      "            num_stages=4,\n",
      "            out_indices=(0, 1, 2, 3),\n",
      "            frozen_stages=1,\n",
      "            norm_cfg=dict(type='BN', requires_grad=True),\n",
      "            norm_eval=True,\n",
      "            style='pytorch',\n",
      "            init_cfg=dict(\n",
      "                type='Pretrained', checkpoint='torchvision://resnet50')),\n",
      "        neck=dict(\n",
      "            type='FPN',\n",
      "            in_channels=[256, 512, 1024, 2048],\n",
      "            out_channels=256,\n",
      "            num_outs=5),\n",
      "        rpn_head=dict(\n",
      "            type='RPNHead',\n",
      "            in_channels=256,\n",
      "            feat_channels=256,\n",
      "            anchor_generator=dict(\n",
      "                type='AnchorGenerator',\n",
      "                scales=[8],\n",
      "                ratios=[0.5, 1.0, 2.0],\n",
      "                strides=[4, 8, 16, 32, 64]),\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[1.0, 1.0, 1.0, 1.0],\n",
      "                clip_border=False),\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "            loss_bbox=dict(\n",
      "                type='SmoothL1Loss', beta=0.1111111111111111,\n",
      "                loss_weight=1.0)),\n",
      "        roi_head=dict(\n",
      "            type='StandardRoIHead',\n",
      "            bbox_roi_extractor=dict(\n",
      "                type='SingleRoIExtractor',\n",
      "                roi_layer=dict(\n",
      "                    type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "                out_channels=256,\n",
      "                featmap_strides=[4, 8, 16, 32]),\n",
      "            bbox_head=dict(\n",
      "                type='Shared2FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=2,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.1, 0.1, 0.2, 0.2],\n",
      "                    clip_border=False),\n",
      "                reg_class_agnostic=False,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='SmoothL1Loss', loss_weight=1.0))),\n",
      "        train_cfg=dict(\n",
      "            rpn=dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.7,\n",
      "                    neg_iou_thr=0.3,\n",
      "                    min_pos_iou=0.3,\n",
      "                    match_low_quality=True,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=256,\n",
      "                    pos_fraction=0.5,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=False),\n",
      "                allowed_border=-1,\n",
      "                pos_weight=-1,\n",
      "                debug=False),\n",
      "            rpn_proposal=dict(\n",
      "                nms_pre=2000,\n",
      "                max_per_img=1000,\n",
      "                nms=dict(type='nms', iou_threshold=0.7),\n",
      "                min_bbox_size=0),\n",
      "            rcnn=dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    min_pos_iou=0.5,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False)),\n",
      "        test_cfg=dict(\n",
      "            rpn=dict(\n",
      "                nms_pre=1000,\n",
      "                max_per_img=1000,\n",
      "                nms=dict(type='nms', iou_threshold=0.7),\n",
      "                min_bbox_size=0),\n",
      "            rcnn=dict(\n",
      "                score_thr=0.05,\n",
      "                nms=dict(type='nms', iou_threshold=0.5),\n",
      "                max_per_img=100)),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint=\n",
      "            'http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth'\n",
      "        )))\n",
      "dataset_type = 'CocoDataset'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile', to_float32=True),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        type='Resize',\n",
      "        img_scale=(1088, 1088),\n",
      "        ratio_range=(0.8, 1.2),\n",
      "        keep_ratio=True,\n",
      "        bbox_clip_border=False),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='RandomCrop', crop_size=(1088, 1088), bbox_clip_border=False),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1088, 1088),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data_root = 'data/VisDrone_MOT_tiny/'\n",
      "data = dict(\n",
      "    samples_per_gpu=2,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/VisDrone_MOT_tiny/train/cocoformat.json',\n",
      "        img_prefix='data/VisDrone_MOT_tiny/train/',\n",
      "        classes=('pedestrian', 'people'),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile', to_float32=True),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                type='Resize',\n",
      "                img_scale=(1088, 1088),\n",
      "                ratio_range=(0.8, 1.2),\n",
      "                keep_ratio=True,\n",
      "                bbox_clip_border=False),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(\n",
      "                type='RandomCrop',\n",
      "                crop_size=(1088, 1088),\n",
      "                bbox_clip_border=False),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/VisDrone_MOT_tiny/test/cocoformat.json',\n",
      "        img_prefix='data/VisDrone_MOT_tiny/test/',\n",
      "        classes=('pedestrian', 'people'),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1088, 1088),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/VisDrone_MOT_tiny/test/cocoformat.json',\n",
      "        img_prefix='data/VisDrone_MOT_tiny/test/',\n",
      "        classes=('pedestrian', 'people'),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1088, 1088),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "evaluation = dict(metric=['bbox'])\n",
      "optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "USE_MMDET = True\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=100,\n",
      "    warmup_ratio=0.01,\n",
      "    step=[3])\n",
      "total_epochs = 4\n",
      "work_dir = './tutorial_exps/detector'\n",
      "seed = 0\n",
      "device = 'cuda'\n",
      "gpu_ids = [1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "from mmdet.apis import set_random_seed\n",
    "cfg = mmcv.Config.fromfile('./configs/det/faster-rcnn_r50_fpn_4e_visdrone_mot.py')\n",
    "cfg.data_root = 'data/VisDrone_MOT_tiny/'\n",
    "cfg.data.test.ann_file = cfg.data.test.ann_file.replace('data/VisDrone_MOT/','data/VisDrone_MOT_tiny/')\n",
    "cfg.data.train.ann_file = cfg.data.train.ann_file.replace('data/VisDrone_MOT/','data/VisDrone_MOT_tiny/')\n",
    "cfg.data.val.ann_file = cfg.data.val.ann_file.replace('data/VisDrone_MOT/','data/VisDrone_MOT_tiny/')\n",
    "\n",
    "cfg.data.test.img_prefix = cfg.data.test.img_prefix.replace('data/VisDrone_MOT/','data/VisDrone_MOT_tiny/')\n",
    "cfg.data.train.img_prefix = cfg.data.train.img_prefix.replace('data/VisDrone_MOT/','data/VisDrone_MOT_tiny/')\n",
    "cfg.data.val.img_prefix = cfg.data.val.img_prefix.replace('data/VisDrone_MOT/','data/VisDrone_MOT_tiny/')\n",
    "\n",
    "cfg.work_dir = './tutorial_exps/detector'\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.device = \"cuda\"\n",
    "# cfg.gpu_ids = range(1)\n",
    "cfg.gpu_ids = [1]\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检测器训练&验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:32:12,775 - mmcv - INFO - initialize FasterRCNN with init_cfg {'type': 'Pretrained', 'checkpoint': 'http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth'}\n",
      "2022-11-08 15:32:12,775 - mmcv - INFO - load model from: http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth\n",
      "2022-11-08 15:32:12,776 - mmcv - INFO - load checkpoint from http path: http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth\n",
      "2022-11-08 15:32:12,871 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([3, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([3]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([8]).\n",
      "2022-11-08 15:32:13,025 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
      "2022-11-08 15:32:13,035 - mmdet - INFO - Start running, host: root@5f2d80d40d9d, work_dir: /workdir/tutorial_exps/detector\n",
      "2022-11-08 15:32:13,036 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-11-08 15:32:13,036 - mmdet - INFO - workflow: [('train', 1)], max: 4 epochs\n",
      "2022-11-08 15:32:13,036 - mmdet - INFO - Checkpoints will be saved to /workdir/tutorial_exps/detector by HardDiskBackend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:32:31,467 - mmdet - INFO - Epoch [1][50/164]\tlr: 9.902e-03, eta: 0:03:42, time: 0.367, data_time: 0.047, memory: 2946, loss_rpn_cls: 0.0418, loss_rpn_bbox: 0.0697, loss_cls: 0.5932, acc: 74.4766, loss_bbox: 0.4064, loss: 1.1112\n",
      "2022-11-08 15:32:47,810 - mmdet - INFO - Epoch [1][100/164]\tlr: 1.980e-02, eta: 0:03:12, time: 0.327, data_time: 0.005, memory: 2946, loss_rpn_cls: 0.0235, loss_rpn_bbox: 0.0680, loss_cls: 0.3227, acc: 86.5273, loss_bbox: 0.2488, loss: 0.6630\n",
      "2022-11-08 15:33:04,338 - mmdet - INFO - Epoch [1][150/164]\tlr: 2.000e-02, eta: 0:02:52, time: 0.331, data_time: 0.005, memory: 2946, loss_rpn_cls: 0.0241, loss_rpn_bbox: 0.0575, loss_cls: 0.2914, acc: 87.7500, loss_bbox: 0.2071, loss: 0.5801\n",
      "2022-11-08 15:33:08,932 - mmdet - INFO - Saving checkpoint at 1 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 118/118, 14.7 task/s, elapsed: 8s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:33:17,743 - mmdet - INFO - Evaluating bbox...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:33:19,413 - mmdet - INFO - \n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.235\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.576\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.138\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.109\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.292\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.412\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.405\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.405\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.405\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.257\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.443\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.451\n",
      "\n",
      "2022-11-08 15:33:19,414 - mmdet - INFO - \n",
      "+------------+-------+----------+-------+\n",
      "| category   | AP    | category | AP    |\n",
      "+------------+-------+----------+-------+\n",
      "| pedestrian | 0.227 | people   | 0.244 |\n",
      "+------------+-------+----------+-------+\n",
      "2022-11-08 15:33:19,419 - mmdet - INFO - Epoch(val) [1][118]\tbbox_mAP: 0.2350, bbox_mAP_50: 0.5760, bbox_mAP_75: 0.1380, bbox_mAP_s: 0.1090, bbox_mAP_m: 0.2920, bbox_mAP_l: 0.4120, bbox_mAP_copypaste: 0.235 0.576 0.138 0.109 0.292 0.412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=1.50s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.14s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:33:37,954 - mmdet - INFO - Epoch [2][50/164]\tlr: 2.000e-02, eta: 0:02:23, time: 0.369, data_time: 0.047, memory: 2946, loss_rpn_cls: 0.0159, loss_rpn_bbox: 0.0513, loss_cls: 0.2530, acc: 89.3105, loss_bbox: 0.1911, loss: 0.5114\n",
      "2022-11-08 15:33:54,391 - mmdet - INFO - Epoch [2][100/164]\tlr: 2.000e-02, eta: 0:02:07, time: 0.329, data_time: 0.005, memory: 2946, loss_rpn_cls: 0.0142, loss_rpn_bbox: 0.0482, loss_cls: 0.2522, acc: 89.1348, loss_bbox: 0.1745, loss: 0.4892\n",
      "2022-11-08 15:34:10,944 - mmdet - INFO - Epoch [2][150/164]\tlr: 2.000e-02, eta: 0:01:51, time: 0.331, data_time: 0.005, memory: 2946, loss_rpn_cls: 0.0100, loss_rpn_bbox: 0.0420, loss_cls: 0.2257, acc: 90.3711, loss_bbox: 0.1663, loss: 0.4440\n",
      "2022-11-08 15:34:15,551 - mmdet - INFO - Saving checkpoint at 2 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 118/118, 14.4 task/s, elapsed: 8s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:34:24,461 - mmdet - INFO - Evaluating bbox...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:34:25,779 - mmdet - INFO - \n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.259\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.585\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.178\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.082\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.319\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.409\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.400\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.400\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.400\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.462\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.480\n",
      "\n",
      "2022-11-08 15:34:25,779 - mmdet - INFO - \n",
      "+------------+-------+----------+-------+\n",
      "| category   | AP    | category | AP    |\n",
      "+------------+-------+----------+-------+\n",
      "| pedestrian | 0.246 | people   | 0.272 |\n",
      "+------------+-------+----------+-------+\n",
      "2022-11-08 15:34:25,783 - mmdet - INFO - Epoch(val) [2][118]\tbbox_mAP: 0.2590, bbox_mAP_50: 0.5850, bbox_mAP_75: 0.1780, bbox_mAP_s: 0.0820, bbox_mAP_m: 0.3190, bbox_mAP_l: 0.4090, bbox_mAP_copypaste: 0.259 0.585 0.178 0.082 0.319 0.409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=1.18s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.12s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:34:44,356 - mmdet - INFO - Epoch [3][50/164]\tlr: 2.000e-02, eta: 0:01:29, time: 0.370, data_time: 0.047, memory: 2946, loss_rpn_cls: 0.0123, loss_rpn_bbox: 0.0382, loss_cls: 0.2172, acc: 90.7383, loss_bbox: 0.1578, loss: 0.4256\n",
      "2022-11-08 15:35:00,859 - mmdet - INFO - Epoch [3][100/164]\tlr: 2.000e-02, eta: 0:01:13, time: 0.330, data_time: 0.005, memory: 2946, loss_rpn_cls: 0.0118, loss_rpn_bbox: 0.0356, loss_cls: 0.1983, acc: 91.6914, loss_bbox: 0.1426, loss: 0.3884\n",
      "2022-11-08 15:35:17,484 - mmdet - INFO - Epoch [3][150/164]\tlr: 2.000e-02, eta: 0:00:57, time: 0.333, data_time: 0.005, memory: 2946, loss_rpn_cls: 0.0098, loss_rpn_bbox: 0.0370, loss_cls: 0.2002, acc: 91.4473, loss_bbox: 0.1422, loss: 0.3893\n",
      "2022-11-08 15:35:22,106 - mmdet - INFO - Saving checkpoint at 3 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 118/118, 14.7 task/s, elapsed: 8s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:35:30,921 - mmdet - INFO - Evaluating bbox...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:35:32,307 - mmdet - INFO - \n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.268\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.658\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.158\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.088\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.329\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.418\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.396\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.396\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.396\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.454\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.481\n",
      "\n",
      "2022-11-08 15:35:32,308 - mmdet - INFO - \n",
      "+------------+-------+----------+-------+\n",
      "| category   | AP    | category | AP    |\n",
      "+------------+-------+----------+-------+\n",
      "| pedestrian | 0.257 | people   | 0.280 |\n",
      "+------------+-------+----------+-------+\n",
      "2022-11-08 15:35:32,311 - mmdet - INFO - Epoch(val) [3][118]\tbbox_mAP: 0.2680, bbox_mAP_50: 0.6580, bbox_mAP_75: 0.1580, bbox_mAP_s: 0.0880, bbox_mAP_m: 0.3290, bbox_mAP_l: 0.4180, bbox_mAP_copypaste: 0.268 0.658 0.158 0.088 0.329 0.418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=1.25s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.11s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:35:50,964 - mmdet - INFO - Epoch [4][50/164]\tlr: 2.000e-03, eta: 0:00:36, time: 0.371, data_time: 0.047, memory: 2946, loss_rpn_cls: 0.0097, loss_rpn_bbox: 0.0268, loss_cls: 0.1722, acc: 92.7363, loss_bbox: 0.1191, loss: 0.3278\n",
      "2022-11-08 15:36:07,483 - mmdet - INFO - Epoch [4][100/164]\tlr: 2.000e-03, eta: 0:00:20, time: 0.330, data_time: 0.005, memory: 2946, loss_rpn_cls: 0.0069, loss_rpn_bbox: 0.0244, loss_cls: 0.1795, acc: 92.2422, loss_bbox: 0.1184, loss: 0.3293\n",
      "2022-11-08 15:36:24,184 - mmdet - INFO - Epoch [4][150/164]\tlr: 2.000e-03, eta: 0:00:04, time: 0.334, data_time: 0.005, memory: 2946, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0222, loss_cls: 0.1677, acc: 92.8398, loss_bbox: 0.1173, loss: 0.3126\n",
      "2022-11-08 15:36:28,809 - mmdet - INFO - Saving checkpoint at 4 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 118/118, 14.5 task/s, elapsed: 8s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:36:37,725 - mmdet - INFO - Evaluating bbox...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:36:38,772 - mmdet - INFO - \n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.287\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.639\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.202\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.072\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.354\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.438\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.393\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.393\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.393\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.142\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.463\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.519\n",
      "\n",
      "2022-11-08 15:36:38,773 - mmdet - INFO - \n",
      "+------------+-------+----------+-------+\n",
      "| category   | AP    | category | AP    |\n",
      "+------------+-------+----------+-------+\n",
      "| pedestrian | 0.276 | people   | 0.297 |\n",
      "+------------+-------+----------+-------+\n",
      "2022-11-08 15:36:38,776 - mmdet - INFO - Epoch(val) [4][118]\tbbox_mAP: 0.2870, bbox_mAP_50: 0.6390, bbox_mAP_75: 0.2020, bbox_mAP_s: 0.0720, bbox_mAP_m: 0.3540, bbox_mAP_l: 0.4380, bbox_mAP_copypaste: 0.287 0.639 0.202 0.072 0.354 0.438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=0.94s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.09s).\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmtrack.datasets import build_dataset\n",
    "from mmdet.apis import train_detector as train_model\n",
    "from mmdet.models import build_detector as build_model\n",
    "\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "model = build_model(cfg.model.detector)\n",
    "model.init_weights()\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "train_model(model, datasets, cfg, validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReID模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集处理（转化为ReID数据集）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove './data/VisDrone_MOT_tiny/test/reid': No such file or directory\n",
      "rm: cannot remove './data/VisDrone_MOT_tiny/test/reid_meta': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm -r ./data/VisDrone_MOT_tiny/train/reid \n",
    "!rm -r ./data/VisDrone_MOT_tiny/train/reid_meta\n",
    "!rm -r ./data/VisDrone_MOT_tiny/test/reid \n",
    "!rm -r ./data/VisDrone_MOT_tiny/test/reid_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corp reid images...\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:04<00:00,  2.23s/it]\n",
      "generate reid labels...\n"
     ]
    }
   ],
   "source": [
    "!python ./tools/convert_datasets/visdronemot/visdronemot2reid.py -d ./data/VisDrone_MOT_tiny/train --min-per-person=4 --max-per-person=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corp reid images...\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.47s/it]\n",
      "generate reid labels...\n"
     ]
    }
   ],
   "source": [
    "!python ./tools/convert_datasets/visdronemot/visdronemot2reid.py -d ./data/VisDrone_MOT_tiny/test --min-per-person=4 --max-per-person=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 修改训练配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "dataset_type = 'ReIDDataset'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadMultiImagesFromFile', to_float32=True),\n",
      "    dict(\n",
      "        type='SeqResize',\n",
      "        img_scale=(128, 256),\n",
      "        share_params=False,\n",
      "        keep_ratio=False,\n",
      "        bbox_clip_border=False,\n",
      "        override=False),\n",
      "    dict(\n",
      "        type='SeqRandomFlip',\n",
      "        share_params=False,\n",
      "        flip_ratio=0.5,\n",
      "        direction='horizontal'),\n",
      "    dict(\n",
      "        type='SeqNormalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='VideoCollect', keys=['img', 'gt_label']),\n",
      "    dict(type='ReIDFormatBundle')\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='Resize', img_scale=(128, 256), keep_ratio=False),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='ImageToTensor', keys=['img']),\n",
      "    dict(type='Collect', keys=['img'], meta_keys=[])\n",
      "]\n",
      "data_root = 'data/VisDrone_MOT_tiny/'\n",
      "data = dict(\n",
      "    samples_per_gpu=1,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='ReIDDataset',\n",
      "        triplet_sampler=dict(num_ids=8, ins_per_id=4),\n",
      "        data_prefix='data/VisDrone_MOT_tiny/train/reid',\n",
      "        ann_file='data/VisDrone_MOT_tiny/train/reid_meta/labels.txt',\n",
      "        pipeline=[\n",
      "            dict(type='LoadMultiImagesFromFile', to_float32=True),\n",
      "            dict(\n",
      "                type='SeqResize',\n",
      "                img_scale=(128, 256),\n",
      "                share_params=False,\n",
      "                keep_ratio=False,\n",
      "                bbox_clip_border=False,\n",
      "                override=False),\n",
      "            dict(\n",
      "                type='SeqRandomFlip',\n",
      "                share_params=False,\n",
      "                flip_ratio=0.5,\n",
      "                direction='horizontal'),\n",
      "            dict(\n",
      "                type='SeqNormalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='VideoCollect', keys=['img', 'gt_label']),\n",
      "            dict(type='ReIDFormatBundle')\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='ReIDDataset',\n",
      "        triplet_sampler=None,\n",
      "        data_prefix='data/VisDrone_MOT_tiny/test/reid',\n",
      "        ann_file='data/VisDrone_MOT_tiny/test/reid_meta/labels.txt',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='Resize', img_scale=(128, 256), keep_ratio=False),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'], meta_keys=[])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='ReIDDataset',\n",
      "        triplet_sampler=None,\n",
      "        data_prefix='data/VisDrone_MOT_tiny/test/reid',\n",
      "        ann_file='data/VisDrone_MOT_tiny/test/reid_meta/labels.txt',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='Resize', img_scale=(128, 256), keep_ratio=False),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'], meta_keys=[])\n",
      "        ]))\n",
      "evaluation = dict(interval=1, metric='mAP')\n",
      "optimizer = dict(type='SGD', lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "TRAIN_REID = True\n",
      "model = dict(\n",
      "    reid=dict(\n",
      "        type='BaseReID',\n",
      "        backbone=dict(\n",
      "            type='ResNet',\n",
      "            depth=50,\n",
      "            num_stages=4,\n",
      "            out_indices=(3, ),\n",
      "            style='pytorch'),\n",
      "        neck=dict(type='GlobalAveragePooling', kernel_size=(8, 4), stride=1),\n",
      "        head=dict(\n",
      "            type='LinearReIDHead',\n",
      "            num_fcs=1,\n",
      "            in_channels=2048,\n",
      "            fc_channels=1024,\n",
      "            out_channels=128,\n",
      "            num_classes=380,\n",
      "            loss=dict(type='CrossEntropyLoss', loss_weight=1.0),\n",
      "            loss_pairwise=dict(\n",
      "                type='TripletLoss', margin=0.3, loss_weight=1.0),\n",
      "            norm_cfg=dict(type='BN1d'),\n",
      "            act_cfg=dict(type='ReLU')),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth'\n",
      "        )))\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=200,\n",
      "    warmup_ratio=0.005,\n",
      "    step=[1])\n",
      "total_epochs = 2\n",
      "work_dir = './tutorial_exps/reid'\n",
      "seed = 0\n",
      "device = 'cuda'\n",
      "gpu_ids = [0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "from mmdet.apis import set_random_seed\n",
    "cfg = mmcv.Config.fromfile('./configs/reid/resnet50_b32x8_VisDroneMOT.py')\n",
    "cfg.data_root = 'data/VisDrone_MOT_tiny/'\n",
    "# cfg.data.train.ann_file = 'data/VisDrone_MOT_tiny/train/reid_meta/train.txt'\n",
    "cfg.data.train.ann_file = cfg.data.train.ann_file.replace('data/VisDrone_MOT/','data/VisDrone_MOT_tiny/')\n",
    "cfg.data.val.ann_file = cfg.data.val.ann_file.replace('data/VisDrone_MOT/','data/VisDrone_MOT_tiny/')\n",
    "cfg.data.test.ann_file = cfg.data.test.ann_file.replace('data/VisDrone_MOT/','data/VisDrone_MOT_tiny/')\n",
    "\n",
    "cfg.data.train.data_prefix = cfg.data.train.data_prefix.replace('data/VisDrone_MOT/','data/VisDrone_MOT_tiny/')\n",
    "cfg.data.val.data_prefix = cfg.data.val.data_prefix.replace('data/VisDrone_MOT/','data/VisDrone_MOT_tiny/')\n",
    "cfg.data.test.data_prefix = cfg.data.test.data_prefix.replace('data/VisDrone_MOT/','data/VisDrone_MOT_tiny/')\n",
    "\n",
    "# learning policy\n",
    "cfg.lr_config = dict(\n",
    "    policy='step',\n",
    "    warmup='linear',\n",
    "    warmup_iters=200,\n",
    "    warmup_ratio=1.0 / 200,\n",
    "    step=[1])\n",
    "cfg.total_epochs = 2\n",
    "\n",
    "cfg.work_dir = './tutorial_exps/reid'\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.device = \"cuda\"\n",
    "# cfg.gpu_ids = range(1)\n",
    "cfg.gpu_ids = [0]\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReID模块训练&验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 03:12:05,701 - mmcv - INFO - initialize BaseReID with init_cfg {'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth'}\n",
      "2022-11-08 03:12:05,702 - mmcv - INFO - load model from: https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth\n",
      "2022-11-08 03:12:05,702 - mmcv - INFO - load checkpoint from http path: https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth\n",
      "2022-11-08 03:12:05,747 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: head.fc.weight, head.fc.bias\n",
      "\n",
      "missing keys in source state_dict: head.fcs.0.fc.weight, head.fcs.0.fc.bias, head.fcs.0.bn.weight, head.fcs.0.bn.bias, head.fcs.0.bn.running_mean, head.fcs.0.bn.running_var, head.fc_out.weight, head.fc_out.bias, head.bn.weight, head.bn.bias, head.bn.running_mean, head.bn.running_var, head.classifier.weight, head.classifier.bias\n",
      "\n",
      "2022-11-08 03:12:05,806 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
      "2022-11-08 03:12:05,810 - mmdet - INFO - Start running, host: root@36f2fe4146ba, work_dir: /workdir/tutorial_exps/reid\n",
      "2022-11-08 03:12:05,811 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-11-08 03:12:05,811 - mmdet - INFO - workflow: [('train', 1)], max: 2 epochs\n",
      "2022-11-08 03:12:05,811 - mmdet - INFO - Checkpoints will be saved to /workdir/tutorial_exps/reid by HardDiskBackend.\n",
      "2022-11-08 03:12:14,529 - mmdet - INFO - Epoch [1][50/604]\tlr: 2.488e-02, eta: 0:03:20, time: 0.173, data_time: 0.045, memory: 2587, triplet_loss: 1.8551, ce_loss: 5.2344, top-1: 12.6875, loss: 7.0895\n",
      "2022-11-08 03:12:21,125 - mmdet - INFO - Epoch [1][100/604]\tlr: 4.975e-02, eta: 0:02:49, time: 0.132, data_time: 0.004, memory: 2587, triplet_loss: 3.4001, ce_loss: 5.3747, top-1: 5.5625, loss: 8.7748\n",
      "2022-11-08 03:12:27,675 - mmdet - INFO - Epoch [1][150/604]\tlr: 7.463e-02, eta: 0:02:33, time: 0.131, data_time: 0.003, memory: 2587, triplet_loss: 3.0858, ce_loss: 4.4076, top-1: 9.0000, loss: 7.4933\n",
      "2022-11-08 03:12:34,237 - mmdet - INFO - Epoch [1][200/604]\tlr: 9.950e-02, eta: 0:02:22, time: 0.131, data_time: 0.003, memory: 2587, triplet_loss: 1.9091, ce_loss: 3.6639, top-1: 11.0625, loss: 5.5730\n",
      "2022-11-08 03:12:40,793 - mmdet - INFO - Epoch [1][250/604]\tlr: 1.000e-01, eta: 0:02:13, time: 0.131, data_time: 0.003, memory: 2587, triplet_loss: 1.1189, ce_loss: 3.3164, top-1: 15.5000, loss: 4.4353\n",
      "2022-11-08 03:12:47,352 - mmdet - INFO - Epoch [1][300/604]\tlr: 1.000e-01, eta: 0:02:05, time: 0.131, data_time: 0.003, memory: 2587, triplet_loss: 0.6836, ce_loss: 2.8022, top-1: 21.1875, loss: 3.4858\n",
      "2022-11-08 03:12:53,922 - mmdet - INFO - Epoch [1][350/604]\tlr: 1.000e-01, eta: 0:01:57, time: 0.131, data_time: 0.003, memory: 2587, triplet_loss: 0.4619, ce_loss: 2.5718, top-1: 27.0625, loss: 3.0336\n",
      "2022-11-08 03:13:00,497 - mmdet - INFO - Epoch [1][400/604]\tlr: 1.000e-01, eta: 0:01:50, time: 0.131, data_time: 0.003, memory: 2587, triplet_loss: 0.3443, ce_loss: 2.4024, top-1: 32.2500, loss: 2.7468\n",
      "2022-11-08 03:13:07,070 - mmdet - INFO - Epoch [1][450/604]\tlr: 1.000e-01, eta: 0:01:43, time: 0.131, data_time: 0.003, memory: 2587, triplet_loss: 0.5290, ce_loss: 2.3811, top-1: 29.2500, loss: 2.9101\n",
      "2022-11-08 03:13:13,646 - mmdet - INFO - Epoch [1][500/604]\tlr: 1.000e-01, eta: 0:01:35, time: 0.132, data_time: 0.003, memory: 2587, triplet_loss: 0.4420, ce_loss: 2.5078, top-1: 26.1875, loss: 2.9498\n",
      "2022-11-08 03:13:20,229 - mmdet - INFO - Epoch [1][550/604]\tlr: 1.000e-01, eta: 0:01:28, time: 0.132, data_time: 0.003, memory: 2587, triplet_loss: 0.4446, ce_loss: 2.4373, top-1: 29.9375, loss: 2.8819\n",
      "2022-11-08 03:13:26,804 - mmdet - INFO - Epoch [1][600/604]\tlr: 1.000e-01, eta: 0:01:22, time: 0.131, data_time: 0.003, memory: 2587, triplet_loss: 0.3462, ce_loss: 2.3239, top-1: 31.5000, loss: 2.6700\n",
      "2022-11-08 03:13:27,313 - mmdet - INFO - Saving checkpoint at 1 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 294/294, 132.5 task/s, elapsed: 2s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 03:13:30,394 - mmdet - INFO - Epoch(val) [1][294]\tmAP: 0.6870\n",
      "2022-11-08 03:13:39,146 - mmdet - INFO - Epoch [2][50/604]\tlr: 1.000e-02, eta: 0:01:15, time: 0.174, data_time: 0.045, memory: 2587, triplet_loss: 0.2025, ce_loss: 1.8454, top-1: 41.8750, loss: 2.0479\n",
      "2022-11-08 03:13:45,746 - mmdet - INFO - Epoch [2][100/604]\tlr: 1.000e-02, eta: 0:01:08, time: 0.132, data_time: 0.003, memory: 2587, triplet_loss: 0.1795, ce_loss: 1.4846, top-1: 54.3125, loss: 1.6641\n",
      "2022-11-08 03:13:52,342 - mmdet - INFO - Epoch [2][150/604]\tlr: 1.000e-02, eta: 0:01:01, time: 0.132, data_time: 0.003, memory: 2587, triplet_loss: 0.2270, ce_loss: 1.4436, top-1: 50.8750, loss: 1.6706\n",
      "2022-11-08 03:13:58,934 - mmdet - INFO - Epoch [2][200/604]\tlr: 1.000e-02, eta: 0:00:54, time: 0.132, data_time: 0.003, memory: 2587, triplet_loss: 0.1133, ce_loss: 1.3199, top-1: 56.5625, loss: 1.4332\n",
      "2022-11-08 03:14:05,525 - mmdet - INFO - Epoch [2][250/604]\tlr: 1.000e-02, eta: 0:00:48, time: 0.132, data_time: 0.003, memory: 2587, triplet_loss: 0.1048, ce_loss: 1.2712, top-1: 56.6875, loss: 1.3760\n",
      "2022-11-08 03:14:12,113 - mmdet - INFO - Epoch [2][300/604]\tlr: 1.000e-02, eta: 0:00:41, time: 0.132, data_time: 0.003, memory: 2587, triplet_loss: 0.1247, ce_loss: 1.2448, top-1: 59.8125, loss: 1.3695\n",
      "2022-11-08 03:14:18,704 - mmdet - INFO - Epoch [2][350/604]\tlr: 1.000e-02, eta: 0:00:34, time: 0.132, data_time: 0.003, memory: 2587, triplet_loss: 0.1507, ce_loss: 1.2830, top-1: 61.1875, loss: 1.4337\n",
      "2022-11-08 03:14:25,289 - mmdet - INFO - Epoch [2][400/604]\tlr: 1.000e-02, eta: 0:00:27, time: 0.132, data_time: 0.003, memory: 2587, triplet_loss: 0.0872, ce_loss: 1.2108, top-1: 58.6250, loss: 1.2980\n",
      "2022-11-08 03:14:31,877 - mmdet - INFO - Epoch [2][450/604]\tlr: 1.000e-02, eta: 0:00:20, time: 0.132, data_time: 0.003, memory: 2587, triplet_loss: 0.1098, ce_loss: 1.0790, top-1: 63.3750, loss: 1.1888\n",
      "2022-11-08 03:14:38,463 - mmdet - INFO - Epoch [2][500/604]\tlr: 1.000e-02, eta: 0:00:14, time: 0.132, data_time: 0.003, memory: 2587, triplet_loss: 0.1026, ce_loss: 1.1048, top-1: 63.3750, loss: 1.2075\n",
      "2022-11-08 03:14:45,050 - mmdet - INFO - Epoch [2][550/604]\tlr: 1.000e-02, eta: 0:00:07, time: 0.132, data_time: 0.003, memory: 2587, triplet_loss: 0.0725, ce_loss: 0.9646, top-1: 67.9375, loss: 1.0372\n",
      "2022-11-08 03:14:51,641 - mmdet - INFO - Epoch [2][600/604]\tlr: 1.000e-02, eta: 0:00:00, time: 0.132, data_time: 0.003, memory: 2587, triplet_loss: 0.1152, ce_loss: 0.9832, top-1: 65.5000, loss: 1.0983\n",
      "2022-11-08 03:14:52,153 - mmdet - INFO - Saving checkpoint at 2 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 294/294, 131.1 task/s, elapsed: 2s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 03:14:55,239 - mmdet - INFO - Epoch(val) [2][294]\tmAP: 0.7610\n"
     ]
    }
   ],
   "source": [
    "from mmtrack.datasets import build_dataset\n",
    "from mmdet.apis import train_detector as train_model\n",
    "from mmtrack.models import build_reid as build_model\n",
    "\n",
    "\n",
    "model = build_model(cfg.model.reid)\n",
    "model.init_weights()\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "\n",
    "train_model(model, datasets, cfg, validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 验证跟踪模型（检测器+跟踪）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    detector=dict(\n",
      "        type='FasterRCNN',\n",
      "        backbone=dict(\n",
      "            type='ResNet',\n",
      "            depth=50,\n",
      "            num_stages=4,\n",
      "            out_indices=(0, 1, 2, 3),\n",
      "            frozen_stages=1,\n",
      "            norm_cfg=dict(type='BN', requires_grad=True),\n",
      "            norm_eval=True,\n",
      "            style='pytorch',\n",
      "            init_cfg=dict(\n",
      "                type='Pretrained', checkpoint='torchvision://resnet50')),\n",
      "        neck=dict(\n",
      "            type='FPN',\n",
      "            in_channels=[256, 512, 1024, 2048],\n",
      "            out_channels=256,\n",
      "            num_outs=5),\n",
      "        rpn_head=dict(\n",
      "            type='RPNHead',\n",
      "            in_channels=256,\n",
      "            feat_channels=256,\n",
      "            anchor_generator=dict(\n",
      "                type='AnchorGenerator',\n",
      "                scales=[8],\n",
      "                ratios=[0.5, 1.0, 2.0],\n",
      "                strides=[4, 8, 16, 32, 64]),\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[1.0, 1.0, 1.0, 1.0],\n",
      "                clip_border=False),\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "            loss_bbox=dict(\n",
      "                type='SmoothL1Loss', beta=0.1111111111111111,\n",
      "                loss_weight=1.0)),\n",
      "        roi_head=dict(\n",
      "            type='StandardRoIHead',\n",
      "            bbox_roi_extractor=dict(\n",
      "                type='SingleRoIExtractor',\n",
      "                roi_layer=dict(\n",
      "                    type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "                out_channels=256,\n",
      "                featmap_strides=[4, 8, 16, 32]),\n",
      "            bbox_head=dict(\n",
      "                type='Shared2FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=2,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.1, 0.1, 0.2, 0.2],\n",
      "                    clip_border=False),\n",
      "                reg_class_agnostic=False,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='SmoothL1Loss', loss_weight=1.0))),\n",
      "        train_cfg=dict(\n",
      "            rpn=dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.7,\n",
      "                    neg_iou_thr=0.3,\n",
      "                    min_pos_iou=0.3,\n",
      "                    match_low_quality=True,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=256,\n",
      "                    pos_fraction=0.5,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=False),\n",
      "                allowed_border=-1,\n",
      "                pos_weight=-1,\n",
      "                debug=False),\n",
      "            rpn_proposal=dict(\n",
      "                nms_pre=2000,\n",
      "                max_per_img=1000,\n",
      "                nms=dict(type='nms', iou_threshold=0.7),\n",
      "                min_bbox_size=0),\n",
      "            rcnn=dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    min_pos_iou=0.5,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False)),\n",
      "        test_cfg=dict(\n",
      "            rpn=dict(\n",
      "                nms_pre=1000,\n",
      "                max_per_img=1000,\n",
      "                nms=dict(type='nms', iou_threshold=0.7),\n",
      "                min_bbox_size=0),\n",
      "            rcnn=dict(\n",
      "                score_thr=0.05,\n",
      "                nms=dict(type='nms', iou_threshold=0.5),\n",
      "                max_per_img=100)),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint='./tutorial_exps/detector/epoch_4.pth')),\n",
      "    type='DeepSORT',\n",
      "    motion=dict(type='KalmanFilter', center_only=False),\n",
      "    reid=dict(\n",
      "        type='BaseReID',\n",
      "        backbone=dict(\n",
      "            type='ResNet',\n",
      "            depth=50,\n",
      "            num_stages=4,\n",
      "            out_indices=(3, ),\n",
      "            style='pytorch'),\n",
      "        neck=dict(type='GlobalAveragePooling', kernel_size=(8, 4), stride=1),\n",
      "        head=dict(\n",
      "            type='LinearReIDHead',\n",
      "            num_fcs=1,\n",
      "            in_channels=2048,\n",
      "            fc_channels=1024,\n",
      "            out_channels=128,\n",
      "            num_classes=380,\n",
      "            loss=dict(type='CrossEntropyLoss', loss_weight=1.0),\n",
      "            loss_pairwise=dict(\n",
      "                type='TripletLoss', margin=0.3, loss_weight=1.0),\n",
      "            norm_cfg=dict(type='BN1d'),\n",
      "            act_cfg=dict(type='ReLU')),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained', checkpoint='./tutorial_exps/reid/epoch_2.pth')),\n",
      "    tracker=dict(\n",
      "        type='SortTracker',\n",
      "        obj_score_thr=0.5,\n",
      "        reid=dict(\n",
      "            num_samples=10,\n",
      "            img_scale=(256, 128),\n",
      "            img_norm_cfg=None,\n",
      "            match_score_thr=2.0),\n",
      "        match_iou_thr=0.5,\n",
      "        momentums=None,\n",
      "        num_tentatives=2,\n",
      "        num_frames_retain=100))\n",
      "dataset_type = 'CocoVideoDataset'\n",
      "classes = ('pedestrian', 'people')\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadMultiImagesFromFile', to_float32=True),\n",
      "    dict(type='SeqLoadAnnotations', with_bbox=True, with_track=True),\n",
      "    dict(\n",
      "        type='SeqResize',\n",
      "        img_scale=(1088, 1088),\n",
      "        share_params=True,\n",
      "        ratio_range=(0.8, 1.2),\n",
      "        keep_ratio=True,\n",
      "        bbox_clip_border=False),\n",
      "    dict(type='SeqPhotoMetricDistortion', share_params=True),\n",
      "    dict(\n",
      "        type='SeqRandomCrop',\n",
      "        share_params=False,\n",
      "        crop_size=(1088, 1088),\n",
      "        bbox_clip_border=False),\n",
      "    dict(type='SeqRandomFlip', share_params=True, flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='SeqNormalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='SeqPad', size_divisor=32),\n",
      "    dict(type='MatchInstances', skip_nomatch=True),\n",
      "    dict(\n",
      "        type='VideoCollect',\n",
      "        keys=[\n",
      "            'img', 'gt_bboxes', 'gt_labels', 'gt_match_indices',\n",
      "            'gt_instance_ids'\n",
      "        ]),\n",
      "    dict(type='SeqDefaultFormatBundle', ref_prefix='ref')\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1088, 1088),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='VideoCollect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data_root = 'data/VisDrone_MOT_tiny/'\n",
      "data = dict(\n",
      "    samples_per_gpu=2,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='CocoVideoDataset',\n",
      "        ann_file='data/VisDrone_MOT_tiny/train/cocoformat.json',\n",
      "        classes=('pedestrian', 'people'),\n",
      "        img_prefix='data/VisDrone_MOT_tiny/train',\n",
      "        ref_img_sampler=None,\n",
      "        pipeline=[\n",
      "            dict(type='LoadMultiImagesFromFile', to_float32=True),\n",
      "            dict(type='SeqLoadAnnotations', with_bbox=True, with_track=True),\n",
      "            dict(\n",
      "                type='SeqResize',\n",
      "                img_scale=(1088, 1088),\n",
      "                share_params=True,\n",
      "                ratio_range=(0.8, 1.2),\n",
      "                keep_ratio=True,\n",
      "                bbox_clip_border=False),\n",
      "            dict(type='SeqPhotoMetricDistortion', share_params=True),\n",
      "            dict(\n",
      "                type='SeqRandomCrop',\n",
      "                share_params=False,\n",
      "                crop_size=(1088, 1088),\n",
      "                bbox_clip_border=False),\n",
      "            dict(type='SeqRandomFlip', share_params=True, flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='SeqNormalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='SeqPad', size_divisor=32),\n",
      "            dict(type='MatchInstances', skip_nomatch=True),\n",
      "            dict(\n",
      "                type='VideoCollect',\n",
      "                keys=[\n",
      "                    'img', 'gt_bboxes', 'gt_labels', 'gt_match_indices',\n",
      "                    'gt_instance_ids'\n",
      "                ]),\n",
      "            dict(type='SeqDefaultFormatBundle', ref_prefix='ref')\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='CocoVideoDataset',\n",
      "        ann_file='data/VisDrone_MOT_tiny/test/cocoformat.json',\n",
      "        classes=('pedestrian', 'people'),\n",
      "        img_prefix='data/VisDrone_MOT_tiny/test',\n",
      "        ref_img_sampler=None,\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1088, 1088),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='VideoCollect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='CocoVideoDataset',\n",
      "        ann_file='data/VisDrone_MOT_tiny/test/cocoformat.json',\n",
      "        classes=('pedestrian', 'people'),\n",
      "        img_prefix='data/VisDrone_MOT_tiny/test',\n",
      "        ref_img_sampler=None,\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1088, 1088),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='VideoCollect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        test_mode=True))\n",
      "optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=100,\n",
      "    warmup_ratio=0.01,\n",
      "    step=[3])\n",
      "total_epochs = 4\n",
      "evaluation = dict(metric=['bbox', 'track'], interval=1)\n",
      "search_metrics = ['MOTA', 'IDF1', 'FN', 'FP', 'IDs', 'MT', 'ML']\n",
      "work_dir = './tutorial_exps'\n",
      "seed = 0\n",
      "device = 'cuda'\n",
      "gpu_ids = [0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "from mmdet.apis import set_random_seed\n",
    "cfg = mmcv.Config.fromfile('./configs/mot/deepsort/deepsort_faster-rcnn_fpn_4e_visdrone_mot.py')\n",
    "cfg.data_root = 'data/VisDrone_MOT_tiny/'\n",
    "cfg.data.test.ann_file = cfg.data.test.ann_file.replace('data/VisDrone_MOT/','data/VisDrone_MOT_tiny/')\n",
    "cfg.data.train.ann_file = cfg.data.train.ann_file.replace('data/VisDrone_MOT/','data/VisDrone_MOT_tiny/')\n",
    "cfg.data.val.ann_file = cfg.data.val.ann_file.replace('data/VisDrone_MOT/','data/VisDrone_MOT_tiny/')\n",
    "\n",
    "cfg.data.test.img_prefix = cfg.data.test.img_prefix.replace('data/VisDrone_MOT/','data/VisDrone_MOT_tiny/')\n",
    "cfg.data.train.img_prefix = cfg.data.train.img_prefix.replace('data/VisDrone_MOT/','data/VisDrone_MOT_tiny/')\n",
    "cfg.data.val.img_prefix = cfg.data.val.img_prefix.replace('data/VisDrone_MOT/','data/VisDrone_MOT_tiny/')\n",
    "\n",
    "cfg.model.detector.init_cfg.checkpoint = './tutorial_exps/detector/epoch_4.pth'\n",
    "cfg.model.reid.init_cfg.checkpoint = './tutorial_exps/reid/epoch_2.pth'\n",
    "\n",
    "cfg.work_dir = './tutorial_exps'\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.device = 'cuda'\n",
    "# cfg.gpu_ids = range(1)\n",
    "cfg.gpu_ids = [0]\n",
    "cfg.data.test.test_mode = True\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:38:37,002 - mmcv - INFO - initialize FasterRCNN with init_cfg {'type': 'Pretrained', 'checkpoint': './tutorial_exps/detector/epoch_4.pth'}\n",
      "2022-11-08 15:38:37,003 - mmcv - INFO - load model from: ./tutorial_exps/detector/epoch_4.pth\n",
      "2022-11-08 15:38:37,004 - mmcv - INFO - load checkpoint from local path: ./tutorial_exps/detector/epoch_4.pth\n",
      "2022-11-08 15:38:37,195 - mmcv - INFO - initialize BaseReID with init_cfg {'type': 'Pretrained', 'checkpoint': './tutorial_exps/reid/epoch_2.pth'}\n",
      "2022-11-08 15:38:37,196 - mmcv - INFO - load model from: ./tutorial_exps/reid/epoch_2.pth\n",
      "2022-11-08 15:38:37,196 - mmcv - INFO - load checkpoint from local path: ./tutorial_exps/reid/epoch_2.pth\n",
      "2022-11-08 15:38:39,118 - mmcv - INFO - \n",
      "detector.backbone.conv1.weight - torch.Size([64, 3, 7, 7]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,119 - mmcv - INFO - \n",
      "detector.backbone.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,119 - mmcv - INFO - \n",
      "detector.backbone.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,120 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,120 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,120 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,121 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,122 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,123 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,123 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,124 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,124 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,124 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,125 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.downsample.1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,125 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.downsample.1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,126 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,126 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,127 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,127 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,127 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,128 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,128 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,129 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,129 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,129 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,130 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,130 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,131 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,131 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,131 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,132 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,132 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,133 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,133 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,136 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,137 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,137 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,137 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,138 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,138 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,139 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,139 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,139 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,140 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.downsample.1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:38:39,140 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.downsample.1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,141 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,142 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,143 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,143 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,144 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,144 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,145 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,145 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,146 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,146 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,147 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,147 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,147 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,148 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,148 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,149 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,149 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,149 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,150 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,151 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,152 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,152 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,153 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,153 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,153 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,154 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,154 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,155 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,155 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,155 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,156 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,156 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,157 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,157 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,157 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,158 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,158 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,158 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.downsample.1.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,159 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.downsample.1.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,159 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,160 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,160 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,160 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,161 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,161 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,162 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,162 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:38:39,162 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,163 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,163 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,164 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,164 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,169 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,169 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,170 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,170 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,171 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,171 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,172 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,172 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,173 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,173 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,174 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,174 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,174 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,175 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,175 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,176 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,176 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,176 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,177 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,177 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,178 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,178 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,178 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,179 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,179 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,180 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,180 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,180 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,181 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,181 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,182 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,182 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,183 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,183 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,187 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,187 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,188 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,189 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,189 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,189 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,190 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,191 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,191 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.downsample.1.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:38:39,192 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.downsample.1.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,192 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,193 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,193 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,193 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,194 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,194 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,195 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,195 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,195 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,196 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,196 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,197 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,197 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,200 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,200 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,201 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,201 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,202 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,203 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.0.conv.weight - torch.Size([256, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,203 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.0.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,203 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.1.conv.weight - torch.Size([256, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,204 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.1.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,205 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.2.conv.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,205 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.2.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,206 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.3.conv.weight - torch.Size([256, 2048, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,206 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.3.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,207 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,207 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.0.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,208 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,208 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.1.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,208 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,209 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.2.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,209 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,210 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.3.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,210 - mmcv - INFO - \n",
      "detector.rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,210 - mmcv - INFO - \n",
      "detector.rpn_head.rpn_conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,211 - mmcv - INFO - \n",
      "detector.rpn_head.rpn_cls.weight - torch.Size([3, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,211 - mmcv - INFO - \n",
      "detector.rpn_head.rpn_cls.bias - torch.Size([3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,212 - mmcv - INFO - \n",
      "detector.rpn_head.rpn_reg.weight - torch.Size([12, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,212 - mmcv - INFO - \n",
      "detector.rpn_head.rpn_reg.bias - torch.Size([12]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,212 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.fc_cls.weight - torch.Size([3, 1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,213 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.fc_cls.bias - torch.Size([3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,213 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.fc_reg.weight - torch.Size([8, 1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,214 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.fc_reg.bias - torch.Size([8]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,214 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,214 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.shared_fcs.0.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,215 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.shared_fcs.1.weight - torch.Size([1024, 1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:38:39,215 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.shared_fcs.1.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:38:39,216 - mmcv - INFO - \n",
      "reid.backbone.conv1.weight - torch.Size([64, 3, 7, 7]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,216 - mmcv - INFO - \n",
      "reid.backbone.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,217 - mmcv - INFO - \n",
      "reid.backbone.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,217 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,217 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,218 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,220 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,221 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,221 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,222 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,222 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,222 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,223 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,223 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.downsample.1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,224 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.downsample.1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,224 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,224 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,225 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,225 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,226 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,226 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,226 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,227 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,227 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,228 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,228 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,228 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,229 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,229 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,230 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,230 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,230 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,231 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,231 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,232 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,232 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,232 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,233 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,233 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,234 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,234 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,235 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,235 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,235 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.downsample.1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,236 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.downsample.1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,236 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,237 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,237 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,238 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,238 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:38:39,239 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,240 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,240 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,241 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,241 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,242 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,242 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,242 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,243 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,243 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,244 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,244 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,245 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,245 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,246 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,246 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,246 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,247 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,247 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,248 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,248 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,249 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,249 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,250 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,250 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,251 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,251 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,252 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,252 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,253 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,253 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,254 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,254 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.downsample.1.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,255 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.downsample.1.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,256 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,256 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,256 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,257 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,257 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,258 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,258 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,259 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,259 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,259 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,260 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,260 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,261 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,261 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,261 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,262 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,262 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:38:39,263 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,263 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,263 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,264 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,264 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,265 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,265 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,265 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,266 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,266 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,267 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,267 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,267 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,268 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,268 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,269 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,269 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,269 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,270 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,270 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,271 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,271 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,271 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,272 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,272 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,273 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,273 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,273 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,274 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,274 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,275 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,275 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,275 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,276 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,276 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,277 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,277 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,285 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,295 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.downsample.1.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,296 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.downsample.1.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,296 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,297 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,297 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,298 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,299 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,299 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,299 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,300 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,300 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,301 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,301 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:38:39,302 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,302 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,302 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,304 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,305 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,305 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,305 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,306 - mmcv - INFO - \n",
      "reid.head.fcs.0.fc.weight - torch.Size([1024, 2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,306 - mmcv - INFO - \n",
      "reid.head.fcs.0.fc.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,307 - mmcv - INFO - \n",
      "reid.head.fcs.0.bn.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,307 - mmcv - INFO - \n",
      "reid.head.fcs.0.bn.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,308 - mmcv - INFO - \n",
      "reid.head.fc_out.weight - torch.Size([128, 1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,308 - mmcv - INFO - \n",
      "reid.head.fc_out.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,310 - mmcv - INFO - \n",
      "reid.head.bn.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,310 - mmcv - INFO - \n",
      "reid.head.bn.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,310 - mmcv - INFO - \n",
      "reid.head.classifier.weight - torch.Size([380, 128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:38:39,311 - mmcv - INFO - \n",
      "reid.head.classifier.bias - torch.Size([380]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The model doesn't have classes\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 118/118, 12.6 task/s, elapsed: 9s, ETA:     0s---CLEAR MOT Evaluation---\n",
      "Accumulating...\n",
      "Evaluating...\n",
      "Rendering...\n",
      "\n",
      "            IDF1  MOTA  MOTP  FP  FN IDSw  Rcll  Prcn MT PT ML  FM\n",
      "pedestrian 59.2% 35.7% 0.744 255 521   60 60.0% 75.4%  7  9  4  57\n",
      "people     54.5% 23.2% 0.744 234 207   18 65.4% 62.6%  6  2  4  14\n",
      "OVERALL    57.6% 31.8% 0.744 489 728   78 61.7% 70.5% 13 11  8  71\n",
      "AVERAGE    56.9% 29.5% 0.744 489 728   78 62.7% 69.0% 13 11  8  71\n",
      "Evaluation finishes with 0.45 s.\n",
      "{'IDF1': 0.576, 'MOTA': 0.318, 'MOTP': 0.744, 'FP': 489, 'FN': 728, 'IDSw': 78, 'Rcll': 0.617, 'Prcn': 0.705, 'MT': 13, 'PT': 11, 'ML': 8, 'FM': 71, 'track_OVERALL_copypaste': '0.576 0.318 0.744 489 728 78 0.617 0.705 13 11 8 71 ', 'track_AVERAGE_copypaste': '0.569 0.295 0.744 489 728 78 0.627 0.690 13 11 8 71 '}\n"
     ]
    }
   ],
   "source": [
    "from mmtrack.datasets import build_dataloader\n",
    "from mmtrack.apis import init_model\n",
    "from mmcv.parallel import MMDataParallel\n",
    "from mmtrack.apis import single_gpu_test\n",
    "from mmtrack.datasets import build_dataset\n",
    "\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "data_loader = build_dataloader(\n",
    "    dataset,\n",
    "    samples_per_gpu=1,\n",
    "    workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "    dist=False,\n",
    "    shuffle=False)\n",
    "\n",
    "# build the model and load checkpoint\n",
    "model = init_model(cfg)\n",
    "\n",
    "model = MMDataParallel(model, device_ids=cfg.gpu_ids)\n",
    "outputs = single_gpu_test(model, data_loader)\n",
    "\n",
    "eval_kwargs = cfg.get('evaluation', {}).copy()\n",
    "# hard-code way to remove EvalHook args\n",
    "eval_hook_args = [\n",
    "    'interval', 'tmpdir', 'start', 'gpu_collect', 'save_best',\n",
    "    'rule', 'by_epoch'\n",
    "]\n",
    "for key in eval_hook_args:\n",
    "    eval_kwargs.pop(key, None)\n",
    "eval_kwargs.update(dict(metric=['track']))\n",
    "metric = dataset.evaluate(outputs, **eval_kwargs)\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推理（检测+跟踪）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:39:11,780 - mmcv - INFO - initialize FasterRCNN with init_cfg {'type': 'Pretrained', 'checkpoint': './tutorial_exps/detector/epoch_4.pth'}\n",
      "2022-11-08 15:39:11,781 - mmcv - INFO - load model from: ./tutorial_exps/detector/epoch_4.pth\n",
      "2022-11-08 15:39:11,782 - mmcv - INFO - load checkpoint from local path: ./tutorial_exps/detector/epoch_4.pth\n",
      "2022-11-08 15:39:11,993 - mmcv - INFO - initialize BaseReID with init_cfg {'type': 'Pretrained', 'checkpoint': './tutorial_exps/reid/epoch_2.pth'}\n",
      "2022-11-08 15:39:11,994 - mmcv - INFO - load model from: ./tutorial_exps/reid/epoch_2.pth\n",
      "2022-11-08 15:39:11,994 - mmcv - INFO - load checkpoint from local path: ./tutorial_exps/reid/epoch_2.pth\n",
      "2022-11-08 15:39:12,113 - mmcv - INFO - \n",
      "detector.backbone.conv1.weight - torch.Size([64, 3, 7, 7]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,113 - mmcv - INFO - \n",
      "detector.backbone.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,114 - mmcv - INFO - \n",
      "detector.backbone.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,114 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,115 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,115 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,115 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,116 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,116 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,117 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,117 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,117 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,118 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,118 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.downsample.1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,120 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.downsample.1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,121 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,121 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,122 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,122 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,123 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,123 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,124 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,124 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,124 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,125 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,125 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,126 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,127 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,128 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,128 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,128 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,129 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,129 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,130 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,130 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,130 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,131 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,131 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,132 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,132 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,132 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,133 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,133 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,134 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.downsample.1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:39:12,134 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.downsample.1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,134 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,135 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,135 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,136 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,136 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,136 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,137 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,137 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,139 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,139 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,140 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,140 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,140 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,141 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,142 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,142 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,142 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,143 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,143 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,144 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,144 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,144 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,145 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,145 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,146 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,146 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,146 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,147 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,147 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,148 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,148 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,148 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,149 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,149 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,150 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,150 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,156 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,156 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.downsample.1.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,157 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.downsample.1.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,157 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,158 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,159 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,159 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,159 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,160 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,160 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,161 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:39:12,161 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,161 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,162 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,162 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,162 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,163 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,163 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,164 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,164 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,164 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,165 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,165 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,168 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,168 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,169 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,169 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,169 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,170 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,170 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,171 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,171 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,171 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,172 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,172 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,173 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,175 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,175 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,175 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,176 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,176 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,177 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,177 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,177 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,178 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,178 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,179 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,179 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,179 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,180 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,180 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,181 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,183 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,183 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,184 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,184 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,185 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,185 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,185 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.downsample.1.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:39:12,186 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.downsample.1.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,186 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,187 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,187 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,187 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,188 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,188 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,189 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,189 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,189 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,190 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,190 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,191 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,191 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,191 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,192 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,192 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,193 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,193 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,193 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.0.conv.weight - torch.Size([256, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,194 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.0.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,194 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.1.conv.weight - torch.Size([256, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,194 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.1.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,195 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.2.conv.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,195 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.2.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,196 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.3.conv.weight - torch.Size([256, 2048, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,196 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.3.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,196 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,197 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.0.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,197 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,198 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.1.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,198 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,198 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.2.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,199 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,199 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.3.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,200 - mmcv - INFO - \n",
      "detector.rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,200 - mmcv - INFO - \n",
      "detector.rpn_head.rpn_conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,200 - mmcv - INFO - \n",
      "detector.rpn_head.rpn_cls.weight - torch.Size([3, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,201 - mmcv - INFO - \n",
      "detector.rpn_head.rpn_cls.bias - torch.Size([3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,201 - mmcv - INFO - \n",
      "detector.rpn_head.rpn_reg.weight - torch.Size([12, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,202 - mmcv - INFO - \n",
      "detector.rpn_head.rpn_reg.bias - torch.Size([12]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,202 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.fc_cls.weight - torch.Size([3, 1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,202 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.fc_cls.bias - torch.Size([3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,203 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.fc_reg.weight - torch.Size([8, 1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,203 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.fc_reg.bias - torch.Size([8]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,204 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,204 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.shared_fcs.0.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,204 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.shared_fcs.1.weight - torch.Size([1024, 1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:39:12,205 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.shared_fcs.1.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 15:39:12,205 - mmcv - INFO - \n",
      "reid.backbone.conv1.weight - torch.Size([64, 3, 7, 7]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,206 - mmcv - INFO - \n",
      "reid.backbone.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,206 - mmcv - INFO - \n",
      "reid.backbone.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,206 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,207 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,207 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,208 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,208 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,209 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,209 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,210 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,211 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,211 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,212 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.downsample.1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,212 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.downsample.1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,212 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,213 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,213 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,214 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,214 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,214 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,215 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,215 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,216 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,216 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,216 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,217 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,217 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,218 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,218 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,218 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,219 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,219 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,220 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,220 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,223 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,230 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,230 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,230 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,231 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,231 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,232 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,232 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,232 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.downsample.1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,233 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.downsample.1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,233 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,234 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,234 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,235 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,235 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:39:12,235 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,239 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,239 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,240 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,240 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,240 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,241 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,241 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,242 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,242 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,242 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,243 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,243 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,244 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,244 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,244 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,245 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,245 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,246 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,246 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,246 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,247 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,250 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,250 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,251 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,251 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,251 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,252 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,252 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,253 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,253 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,253 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,254 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.downsample.1.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,254 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.downsample.1.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,255 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,255 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,255 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,256 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,256 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,256 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,257 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,257 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,258 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,258 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,258 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,259 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,259 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,260 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,260 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,260 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,261 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:39:12,261 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,262 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,262 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,262 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,263 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,263 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,264 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,264 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,264 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,265 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,265 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,266 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,266 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,266 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,267 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,267 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,268 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,268 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,268 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,269 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,269 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,270 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,270 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,270 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,271 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,271 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,272 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,272 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,272 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,273 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,273 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,274 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,274 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,274 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,275 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,275 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,276 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,276 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,276 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.downsample.1.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,277 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.downsample.1.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,277 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,278 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,278 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,278 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,279 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,279 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,280 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,280 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,280 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,285 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,290 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 15:39:12,291 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,292 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,292 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,293 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,293 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,294 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,294 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,295 - mmcv - INFO - \n",
      "reid.head.fcs.0.fc.weight - torch.Size([1024, 2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,295 - mmcv - INFO - \n",
      "reid.head.fcs.0.fc.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,296 - mmcv - INFO - \n",
      "reid.head.fcs.0.bn.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,296 - mmcv - INFO - \n",
      "reid.head.fcs.0.bn.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,297 - mmcv - INFO - \n",
      "reid.head.fc_out.weight - torch.Size([128, 1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,297 - mmcv - INFO - \n",
      "reid.head.fc_out.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,298 - mmcv - INFO - \n",
      "reid.head.bn.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,298 - mmcv - INFO - \n",
      "reid.head.bn.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,299 - mmcv - INFO - \n",
      "reid.head.classifier.weight - torch.Size([380, 128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 15:39:12,299 - mmcv - INFO - \n",
      "reid.head.classifier.bias - torch.Size([380]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The model doesn't have classes\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 109/109, 9.4 task/s, elapsed: 12s, ETA:     0s\n",
      " making the output video at ./demo/visdrone_demo_result.mp4 with a FPS of 10.0\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 109/109, 65.5 task/s, elapsed: 2s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "# run mot demo\n",
    "import mmcv\n",
    "import tempfile\n",
    "from mmtrack.apis import inference_mot, init_model\n",
    "# mot_config = './configs/mot/deepsort/deepsort_faster-rcnn_fpn_4e_visdrone_mot.py'\n",
    "cfg = mmcv.Config.fromfile('./configs/mot/deepsort/deepsort_faster-rcnn_fpn_4e_visdrone_mot.py')\n",
    "cfg.model.detector.init_cfg.checkpoint = './tutorial_exps/detector/epoch_4.pth'\n",
    "cfg.model.reid.init_cfg.checkpoint = './tutorial_exps/reid/epoch_2.pth'\n",
    "input_video = './demo/visdrone_demo.mp4'\n",
    "imgs = mmcv.VideoReader(input_video)\n",
    "# build the model from a config file\n",
    "# mot_model = init_model(mot_config, device='cuda:0')\n",
    "mot_model = init_model(cfg)\n",
    "prog_bar = mmcv.ProgressBar(len(imgs))\n",
    "out_dir = tempfile.TemporaryDirectory()\n",
    "out_path = out_dir.name\n",
    "# test and show/save the images\n",
    "for i, img in enumerate(imgs):\n",
    "    result = inference_mot(mot_model, img, frame_id=i)\n",
    "    mot_model.show_result(\n",
    "            img,\n",
    "            result,\n",
    "            show=False,\n",
    "            wait_time=int(1000. / imgs.fps),\n",
    "            out_file=f'{out_path}/{i:06d}.jpg')\n",
    "    prog_bar.update()\n",
    "\n",
    "output = './demo/visdrone_demo_result.mp4'\n",
    "print(f'\\n making the output video at {output} with a FPS of {imgs.fps}')\n",
    "mmcv.frames2video(out_path, output, fps=imgs.fps, fourcc='mp4v')\n",
    "out_dir.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "356px",
    "width": "297px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
