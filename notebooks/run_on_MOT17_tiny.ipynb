{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集准备（）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-10-28 04:22:30--  https://download.openmmlab.com/mmtracking/data/MOT17_tiny.zip\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 47.102.71.233\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|47.102.71.233|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 344566302 (329M) [application/zip]\n",
      "Saving to: ‘./datasets/MOT17_tiny.zip’\n",
      "\n",
      "MOT17_tiny.zip      100%[===================>] 328.60M  8.90MB/s    in 42s     \n",
      "\n",
      "2022-10-28 04:23:12 (7.92 MB/s) - ‘./datasets/MOT17_tiny.zip’ saved [344566302/344566302]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://download.openmmlab.com/mmtracking/data/MOT17_tiny.zip -P ./datasets\n",
    "!unzip -q ./datasets/MOT17_tiny.zip -d ./datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 转化为coco格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting train set to COCO format\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:01<00:00,  1.78it/s]\n",
      "train has 145 instances.\n",
      "Done! Saved as ./datasets/MOT17_tiny/annotations/train_cocoformat.json and ./datasets/MOT17_tiny/annotations/train_detections.pkl\n",
      "Converting test set to COCO format\n",
      "0it [00:00, ?it/s]\n",
      "test has 0 instances.\n",
      "Done! Saved as ./datasets/MOT17_tiny/annotations/test_cocoformat.json and ./datasets/MOT17_tiny/annotations/test_detections.pkl\n",
      "Converting half-train set to COCO format\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.05s/it]\n",
      "half-train has 104 instances.\n",
      "Done! Saved as ./datasets/MOT17_tiny/annotations/half-train_cocoformat.json and ./datasets/MOT17_tiny/annotations/half-train_detections.pkl\n",
      "Converting half-val set to COCO format\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.06s/it]\n",
      "half-val has 122 instances.\n",
      "Done! Saved as ./datasets/MOT17_tiny/annotations/half-val_cocoformat.json and ./datasets/MOT17_tiny/annotations/half-val_detections.pkl\n",
      "100%|████████████████████████████████████████████| 2/2 [06:34<00:00, 197.12s/it]\n"
     ]
    }
   ],
   "source": [
    "# convert the dataset to coco format\n",
    "!python ./tools/convert_datasets/mot/mot2coco.py -i ./datasets/MOT17_tiny/ -o ./datasets/MOT17_tiny/annotations --split-train --convert-det\n",
    "# crop pedestrian patches from the original dataset for training reid model. It may take a few minutes.\n",
    "!rm -rf ./datasets/MOT17_tiny/reid\n",
    "!python ./tools/convert_datasets/mot/mot2reid.py -i ./datasets/MOT17_tiny/ -o ./datasets/MOT17_tiny/reid --val-split 0.9 --vis-threshold 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/mmcv/__init__.py:21: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  'On January 1, 2023, MMCV will release v2.0.0, in which it will remove '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    detector=dict(\n",
      "        type='FasterRCNN',\n",
      "        backbone=dict(\n",
      "            type='ResNet',\n",
      "            depth=50,\n",
      "            num_stages=4,\n",
      "            out_indices=(0, 1, 2, 3),\n",
      "            frozen_stages=1,\n",
      "            norm_cfg=dict(type='BN', requires_grad=True),\n",
      "            norm_eval=True,\n",
      "            style='pytorch',\n",
      "            init_cfg=dict(\n",
      "                type='Pretrained', checkpoint='torchvision://resnet50')),\n",
      "        neck=dict(\n",
      "            type='FPN',\n",
      "            in_channels=[256, 512, 1024, 2048],\n",
      "            out_channels=256,\n",
      "            num_outs=5),\n",
      "        rpn_head=dict(\n",
      "            type='RPNHead',\n",
      "            in_channels=256,\n",
      "            feat_channels=256,\n",
      "            anchor_generator=dict(\n",
      "                type='AnchorGenerator',\n",
      "                scales=[8],\n",
      "                ratios=[0.5, 1.0, 2.0],\n",
      "                strides=[4, 8, 16, 32, 64]),\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[1.0, 1.0, 1.0, 1.0],\n",
      "                clip_border=False),\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "            loss_bbox=dict(\n",
      "                type='SmoothL1Loss', beta=0.1111111111111111,\n",
      "                loss_weight=1.0)),\n",
      "        roi_head=dict(\n",
      "            type='StandardRoIHead',\n",
      "            bbox_roi_extractor=dict(\n",
      "                type='SingleRoIExtractor',\n",
      "                roi_layer=dict(\n",
      "                    type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "                out_channels=256,\n",
      "                featmap_strides=[4, 8, 16, 32]),\n",
      "            bbox_head=dict(\n",
      "                type='Shared2FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=1,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.1, 0.1, 0.2, 0.2],\n",
      "                    clip_border=False),\n",
      "                reg_class_agnostic=False,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='SmoothL1Loss', loss_weight=1.0))),\n",
      "        train_cfg=dict(\n",
      "            rpn=dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.7,\n",
      "                    neg_iou_thr=0.3,\n",
      "                    min_pos_iou=0.3,\n",
      "                    match_low_quality=True,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=256,\n",
      "                    pos_fraction=0.5,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=False),\n",
      "                allowed_border=-1,\n",
      "                pos_weight=-1,\n",
      "                debug=False),\n",
      "            rpn_proposal=dict(\n",
      "                nms_pre=2000,\n",
      "                max_per_img=1000,\n",
      "                nms=dict(type='nms', iou_threshold=0.7),\n",
      "                min_bbox_size=0),\n",
      "            rcnn=dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    min_pos_iou=0.5,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False)),\n",
      "        test_cfg=dict(\n",
      "            rpn=dict(\n",
      "                nms_pre=1000,\n",
      "                max_per_img=1000,\n",
      "                nms=dict(type='nms', iou_threshold=0.7),\n",
      "                min_bbox_size=0),\n",
      "            rcnn=dict(\n",
      "                score_thr=0.05,\n",
      "                nms=dict(type='nms', iou_threshold=0.5),\n",
      "                max_per_img=100)),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint=\n",
      "            'http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth'\n",
      "        )))\n",
      "dataset_type = 'CocoDataset'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile', to_float32=True),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        type='Resize',\n",
      "        img_scale=(1088, 1088),\n",
      "        ratio_range=(0.8, 1.2),\n",
      "        keep_ratio=True,\n",
      "        bbox_clip_border=False),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='RandomCrop', crop_size=(1088, 1088), bbox_clip_border=False),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1088, 1088),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data_root = 'data/MOT17_tiny/'\n",
      "data = dict(\n",
      "    samples_per_gpu=2,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/MOT17_tiny/annotations/half-train_cocoformat.json',\n",
      "        img_prefix='data/MOT17_tiny/train',\n",
      "        classes=('pedestrian', ),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile', to_float32=True),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                type='Resize',\n",
      "                img_scale=(1088, 1088),\n",
      "                ratio_range=(0.8, 1.2),\n",
      "                keep_ratio=True,\n",
      "                bbox_clip_border=False),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(\n",
      "                type='RandomCrop',\n",
      "                crop_size=(1088, 1088),\n",
      "                bbox_clip_border=False),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/MOT17_tiny/annotations/half-val_cocoformat.json',\n",
      "        img_prefix='data/MOT17_tiny/train',\n",
      "        classes=('pedestrian', ),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1088, 1088),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/MOT17_tiny/annotations/half-val_cocoformat.json',\n",
      "        img_prefix='data/MOT17_tiny/train',\n",
      "        classes=('pedestrian', ),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1088, 1088),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "evaluation = dict(metric=['bbox'])\n",
      "optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "USE_MMDET = True\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=100,\n",
      "    warmup_ratio=0.01,\n",
      "    step=[3])\n",
      "total_epochs = 4\n",
      "work_dir = './tutorial_exps/detector'\n",
      "seed = 0\n",
      "device = 'cuda'\n",
      "gpu_ids = [1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "from mmdet.apis import set_random_seed\n",
    "cfg = mmcv.Config.fromfile('./configs/det/faster-rcnn_r50_fpn_4e_mot17-half.py')\n",
    "cfg.data_root = 'data/MOT17_tiny/'\n",
    "cfg.data.test.ann_file = cfg.data.test.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "cfg.data.train.ann_file = cfg.data.train.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "cfg.data.val.ann_file = cfg.data.val.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "\n",
    "cfg.data.test.img_prefix = cfg.data.test.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "cfg.data.train.img_prefix = cfg.data.train.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "cfg.data.val.img_prefix = cfg.data.val.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
    "\n",
    "cfg.work_dir = './tutorial_exps/detector'\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.device = \"cuda\"\n",
    "# cfg.gpu_ids = range(1)\n",
    "cfg.gpu_ids = [1]\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:16:39,394 - mmcv - INFO - initialize FasterRCNN with init_cfg {'type': 'Pretrained', 'checkpoint': 'http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth'}\n",
      "2022-11-08 14:16:39,395 - mmcv - INFO - load model from: http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth\n",
      "2022-11-08 14:16:39,396 - mmcv - INFO - load checkpoint from http path: http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth\n",
      "Downloading: \"http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth\" to /root/.cache/torch/hub/checkpoints/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3785cf3ab1404b268b35dbcc89c4e1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=167290877.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:16:55,689 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([2, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([2]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([4, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([4]).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loading annotations into memory...\n",
      "Done (t=0.17s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mmdetection/mmdet/utils/compat_config.py:30: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.\n",
      "  'please set `runner` in your config.', UserWarning)\n",
      "2022-11-08 14:16:57,397 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
      "2022-11-08 14:16:57,540 - mmdet - INFO - Start running, host: root@5f2d80d40d9d, work_dir: /workdir/tutorial_exps/detector\n",
      "2022-11-08 14:16:57,541 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-11-08 14:16:57,541 - mmdet - INFO - workflow: [('train', 1)], max: 4 epochs\n",
      "2022-11-08 14:16:57,542 - mmdet - INFO - Checkpoints will be saved to /workdir/tutorial_exps/detector by HardDiskBackend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.11s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448224956/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "2022-11-08 14:17:17,293 - mmdet - INFO - Epoch [1][50/414]\tlr: 9.902e-03, eta: 0:10:31, time: 0.393, data_time: 0.047, memory: 2948, loss_rpn_cls: 0.0944, loss_rpn_bbox: 0.1177, loss_cls: 0.4038, acc: 80.9512, loss_bbox: 0.3394, loss: 0.9553\n",
      "2022-11-08 14:17:34,604 - mmdet - INFO - Epoch [1][100/414]\tlr: 1.980e-02, eta: 0:09:35, time: 0.346, data_time: 0.005, memory: 2948, loss_rpn_cls: 0.0491, loss_rpn_bbox: 0.1251, loss_cls: 0.3192, acc: 86.2480, loss_bbox: 0.2416, loss: 0.7351\n",
      "2022-11-08 14:17:52,177 - mmdet - INFO - Epoch [1][150/414]\tlr: 2.000e-02, eta: 0:09:07, time: 0.352, data_time: 0.005, memory: 2948, loss_rpn_cls: 0.0363, loss_rpn_bbox: 0.1061, loss_cls: 0.3055, acc: 87.0977, loss_bbox: 0.2132, loss: 0.6611\n",
      "2022-11-08 14:18:09,658 - mmdet - INFO - Epoch [1][200/414]\tlr: 2.000e-02, eta: 0:08:44, time: 0.349, data_time: 0.005, memory: 2948, loss_rpn_cls: 0.0234, loss_rpn_bbox: 0.0851, loss_cls: 0.2673, acc: 88.4277, loss_bbox: 0.1836, loss: 0.5594\n",
      "2022-11-08 14:18:27,219 - mmdet - INFO - Epoch [1][250/414]\tlr: 2.000e-02, eta: 0:08:23, time: 0.351, data_time: 0.005, memory: 2948, loss_rpn_cls: 0.0262, loss_rpn_bbox: 0.0797, loss_cls: 0.2673, acc: 88.4746, loss_bbox: 0.1787, loss: 0.5519\n",
      "2022-11-08 14:18:44,495 - mmdet - INFO - Epoch [1][300/414]\tlr: 2.000e-02, eta: 0:08:02, time: 0.345, data_time: 0.005, memory: 2948, loss_rpn_cls: 0.0207, loss_rpn_bbox: 0.0725, loss_cls: 0.2587, acc: 88.9180, loss_bbox: 0.1806, loss: 0.5324\n",
      "2022-11-08 14:19:01,805 - mmdet - INFO - Epoch [1][350/414]\tlr: 2.000e-02, eta: 0:07:43, time: 0.346, data_time: 0.005, memory: 2948, loss_rpn_cls: 0.0125, loss_rpn_bbox: 0.0598, loss_cls: 0.2341, acc: 89.9551, loss_bbox: 0.1597, loss: 0.4661\n",
      "2022-11-08 14:19:19,175 - mmdet - INFO - Epoch [1][400/414]\tlr: 2.000e-02, eta: 0:07:24, time: 0.348, data_time: 0.005, memory: 2948, loss_rpn_cls: 0.0135, loss_rpn_bbox: 0.0571, loss_cls: 0.2128, acc: 91.0137, loss_bbox: 0.1482, loss: 0.4315\n",
      "2022-11-08 14:19:23,814 - mmdet - INFO - Saving checkpoint at 1 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 823/823, 14.3 task/s, elapsed: 57s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:20:23,062 - mmdet - INFO - Evaluating bbox...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.15s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=55.96s).\n",
      "Accumulating evaluation results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:21:20,755 - mmdet - INFO - \n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.481\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.804\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.532\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.074\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.407\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.625\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.529\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.529\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.529\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.073\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.465\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.673\n",
      "\n",
      "2022-11-08 14:21:20,756 - mmdet - INFO - \n",
      "+------------+-------+\n",
      "| category   | AP    |\n",
      "+------------+-------+\n",
      "| pedestrian | 0.481 |\n",
      "+------------+-------+\n",
      "2022-11-08 14:21:20,788 - mmdet - INFO - Epoch(val) [1][823]\tbbox_mAP: 0.4810, bbox_mAP_50: 0.8040, bbox_mAP_75: 0.5320, bbox_mAP_s: 0.0740, bbox_mAP_m: 0.4070, bbox_mAP_l: 0.6250, bbox_mAP_copypaste: 0.481 0.804 0.532 0.074 0.407 0.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=1.33s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:21:39,803 - mmdet - INFO - Epoch [2][50/414]\tlr: 2.000e-02, eta: 0:06:52, time: 0.378, data_time: 0.047, memory: 2948, loss_rpn_cls: 0.0130, loss_rpn_bbox: 0.0610, loss_cls: 0.2159, acc: 90.6836, loss_bbox: 0.1471, loss: 0.4371\n",
      "2022-11-08 14:21:56,736 - mmdet - INFO - Epoch [2][100/414]\tlr: 2.000e-02, eta: 0:06:34, time: 0.339, data_time: 0.005, memory: 2948, loss_rpn_cls: 0.0123, loss_rpn_bbox: 0.0575, loss_cls: 0.2060, acc: 91.2012, loss_bbox: 0.1405, loss: 0.4163\n",
      "2022-11-08 14:22:13,867 - mmdet - INFO - Epoch [2][150/414]\tlr: 2.000e-02, eta: 0:06:16, time: 0.343, data_time: 0.005, memory: 2948, loss_rpn_cls: 0.0126, loss_rpn_bbox: 0.0518, loss_cls: 0.2002, acc: 91.3574, loss_bbox: 0.1325, loss: 0.3971\n",
      "2022-11-08 14:22:31,002 - mmdet - INFO - Epoch [2][200/414]\tlr: 2.000e-02, eta: 0:05:59, time: 0.342, data_time: 0.005, memory: 2948, loss_rpn_cls: 0.0129, loss_rpn_bbox: 0.0613, loss_cls: 0.1994, acc: 91.3672, loss_bbox: 0.1333, loss: 0.4069\n",
      "2022-11-08 14:22:48,168 - mmdet - INFO - Epoch [2][250/414]\tlr: 2.000e-02, eta: 0:05:41, time: 0.343, data_time: 0.005, memory: 2948, loss_rpn_cls: 0.0116, loss_rpn_bbox: 0.0671, loss_cls: 0.1992, acc: 91.4980, loss_bbox: 0.1391, loss: 0.4170\n",
      "2022-11-08 14:23:05,170 - mmdet - INFO - Epoch [2][300/414]\tlr: 2.000e-02, eta: 0:05:24, time: 0.340, data_time: 0.005, memory: 2948, loss_rpn_cls: 0.0128, loss_rpn_bbox: 0.0547, loss_cls: 0.1847, acc: 92.2285, loss_bbox: 0.1253, loss: 0.3775\n",
      "2022-11-08 14:23:22,183 - mmdet - INFO - Epoch [2][350/414]\tlr: 2.000e-02, eta: 0:05:06, time: 0.340, data_time: 0.005, memory: 2948, loss_rpn_cls: 0.0102, loss_rpn_bbox: 0.0484, loss_cls: 0.1834, acc: 92.3027, loss_bbox: 0.1225, loss: 0.3645\n",
      "2022-11-08 14:23:39,221 - mmdet - INFO - Epoch [2][400/414]\tlr: 2.000e-02, eta: 0:04:49, time: 0.341, data_time: 0.005, memory: 2948, loss_rpn_cls: 0.0080, loss_rpn_bbox: 0.0487, loss_cls: 0.1768, acc: 92.5098, loss_bbox: 0.1196, loss: 0.3532\n",
      "2022-11-08 14:23:43,786 - mmdet - INFO - Saving checkpoint at 2 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 823/823, 14.5 task/s, elapsed: 57s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:24:42,072 - mmdet - INFO - Evaluating bbox...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=59.98s).\n",
      "Accumulating evaluation results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:25:43,649 - mmdet - INFO - \n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.476\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.809\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.505\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.081\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.409\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.614\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.528\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.528\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.528\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.093\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.468\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.666\n",
      "\n",
      "2022-11-08 14:25:43,650 - mmdet - INFO - \n",
      "+------------+-------+\n",
      "| category   | AP    |\n",
      "+------------+-------+\n",
      "| pedestrian | 0.476 |\n",
      "+------------+-------+\n",
      "2022-11-08 14:25:43,680 - mmdet - INFO - Epoch(val) [2][823]\tbbox_mAP: 0.4760, bbox_mAP_50: 0.8090, bbox_mAP_75: 0.5050, bbox_mAP_s: 0.0810, bbox_mAP_m: 0.4090, bbox_mAP_l: 0.6140, bbox_mAP_copypaste: 0.476 0.809 0.505 0.081 0.409 0.614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=1.30s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:26:02,806 - mmdet - INFO - Epoch [3][50/414]\tlr: 2.000e-02, eta: 0:04:24, time: 0.381, data_time: 0.047, memory: 2948, loss_rpn_cls: 0.0115, loss_rpn_bbox: 0.0468, loss_cls: 0.1680, acc: 92.7695, loss_bbox: 0.1098, loss: 0.3361\n",
      "2022-11-08 14:26:19,763 - mmdet - INFO - Epoch [3][100/414]\tlr: 2.000e-02, eta: 0:04:07, time: 0.339, data_time: 0.005, memory: 2948, loss_rpn_cls: 0.0096, loss_rpn_bbox: 0.0476, loss_cls: 0.1770, acc: 92.5254, loss_bbox: 0.1169, loss: 0.3511\n",
      "2022-11-08 14:26:36,935 - mmdet - INFO - Epoch [3][150/414]\tlr: 2.000e-02, eta: 0:03:50, time: 0.344, data_time: 0.005, memory: 2948, loss_rpn_cls: 0.0111, loss_rpn_bbox: 0.0580, loss_cls: 0.1772, acc: 92.5449, loss_bbox: 0.1170, loss: 0.3633\n",
      "2022-11-08 14:26:54,046 - mmdet - INFO - Epoch [3][200/414]\tlr: 2.000e-02, eta: 0:03:33, time: 0.342, data_time: 0.005, memory: 2948, loss_rpn_cls: 0.0102, loss_rpn_bbox: 0.0456, loss_cls: 0.1711, acc: 92.7285, loss_bbox: 0.1140, loss: 0.3409\n",
      "2022-11-08 14:27:11,161 - mmdet - INFO - Epoch [3][250/414]\tlr: 2.000e-02, eta: 0:03:16, time: 0.342, data_time: 0.005, memory: 2948, loss_rpn_cls: 0.0101, loss_rpn_bbox: 0.0437, loss_cls: 0.1660, acc: 93.0078, loss_bbox: 0.1166, loss: 0.3363\n",
      "2022-11-08 14:27:28,136 - mmdet - INFO - Epoch [3][300/414]\tlr: 2.000e-02, eta: 0:02:59, time: 0.339, data_time: 0.005, memory: 2948, loss_rpn_cls: 0.0087, loss_rpn_bbox: 0.0426, loss_cls: 0.1517, acc: 93.5938, loss_bbox: 0.1063, loss: 0.3093\n",
      "2022-11-08 14:27:45,198 - mmdet - INFO - Epoch [3][350/414]\tlr: 2.000e-02, eta: 0:02:42, time: 0.341, data_time: 0.006, memory: 2948, loss_rpn_cls: 0.0064, loss_rpn_bbox: 0.0357, loss_cls: 0.1488, acc: 93.6328, loss_bbox: 0.0977, loss: 0.2885\n",
      "2022-11-08 14:28:02,204 - mmdet - INFO - Epoch [3][400/414]\tlr: 2.000e-02, eta: 0:02:25, time: 0.340, data_time: 0.005, memory: 2948, loss_rpn_cls: 0.0069, loss_rpn_bbox: 0.0412, loss_cls: 0.1571, acc: 93.1602, loss_bbox: 0.1071, loss: 0.3123\n",
      "2022-11-08 14:28:06,734 - mmdet - INFO - Saving checkpoint at 3 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 823/823, 14.6 task/s, elapsed: 56s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:29:04,846 - mmdet - INFO - Evaluating bbox...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=48.78s).\n",
      "Accumulating evaluation results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:29:55,119 - mmdet - INFO - \n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.491\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.800\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.545\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.060\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.411\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.639\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.534\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.534\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.534\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.468\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.677\n",
      "\n",
      "2022-11-08 14:29:55,120 - mmdet - INFO - \n",
      "+------------+-------+\n",
      "| category   | AP    |\n",
      "+------------+-------+\n",
      "| pedestrian | 0.491 |\n",
      "+------------+-------+\n",
      "2022-11-08 14:29:55,150 - mmdet - INFO - Epoch(val) [3][823]\tbbox_mAP: 0.4910, bbox_mAP_50: 0.8000, bbox_mAP_75: 0.5450, bbox_mAP_s: 0.0600, bbox_mAP_m: 0.4110, bbox_mAP_l: 0.6390, bbox_mAP_copypaste: 0.491 0.800 0.545 0.060 0.411 0.639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=1.21s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:30:14,282 - mmdet - INFO - Epoch [4][50/414]\tlr: 2.000e-03, eta: 0:02:03, time: 0.381, data_time: 0.047, memory: 2948, loss_rpn_cls: 0.0059, loss_rpn_bbox: 0.0321, loss_cls: 0.1391, acc: 94.1230, loss_bbox: 0.0916, loss: 0.2688\n",
      "2022-11-08 14:30:31,305 - mmdet - INFO - Epoch [4][100/414]\tlr: 2.000e-03, eta: 0:01:46, time: 0.340, data_time: 0.005, memory: 2948, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0259, loss_cls: 0.1295, acc: 94.5742, loss_bbox: 0.0816, loss: 0.2422\n",
      "2022-11-08 14:30:48,483 - mmdet - INFO - Epoch [4][150/414]\tlr: 2.000e-03, eta: 0:01:29, time: 0.344, data_time: 0.005, memory: 2948, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0269, loss_cls: 0.1293, acc: 94.5957, loss_bbox: 0.0831, loss: 0.2443\n",
      "2022-11-08 14:31:05,551 - mmdet - INFO - Epoch [4][200/414]\tlr: 2.000e-03, eta: 0:01:12, time: 0.341, data_time: 0.005, memory: 2948, loss_rpn_cls: 0.0053, loss_rpn_bbox: 0.0281, loss_cls: 0.1359, acc: 94.1719, loss_bbox: 0.0884, loss: 0.2576\n",
      "2022-11-08 14:31:22,757 - mmdet - INFO - Epoch [4][250/414]\tlr: 2.000e-03, eta: 0:00:55, time: 0.344, data_time: 0.005, memory: 2948, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0283, loss_cls: 0.1331, acc: 94.3965, loss_bbox: 0.0876, loss: 0.2540\n",
      "2022-11-08 14:31:39,746 - mmdet - INFO - Epoch [4][300/414]\tlr: 2.000e-03, eta: 0:00:38, time: 0.340, data_time: 0.005, memory: 2948, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0265, loss_cls: 0.1236, acc: 94.8320, loss_bbox: 0.0851, loss: 0.2394\n",
      "2022-11-08 14:31:56,747 - mmdet - INFO - Epoch [4][350/414]\tlr: 2.000e-03, eta: 0:00:21, time: 0.340, data_time: 0.005, memory: 2948, loss_rpn_cls: 0.0051, loss_rpn_bbox: 0.0252, loss_cls: 0.1224, acc: 94.8535, loss_bbox: 0.0816, loss: 0.2344\n",
      "2022-11-08 14:32:13,827 - mmdet - INFO - Epoch [4][400/414]\tlr: 2.000e-03, eta: 0:00:04, time: 0.342, data_time: 0.005, memory: 2948, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0259, loss_cls: 0.1183, acc: 95.0977, loss_bbox: 0.0780, loss: 0.2261\n",
      "2022-11-08 14:32:18,367 - mmdet - INFO - Saving checkpoint at 4 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 823/823, 14.5 task/s, elapsed: 57s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:33:16,816 - mmdet - INFO - Evaluating bbox...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=44.30s).\n",
      "Accumulating evaluation results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:34:02,438 - mmdet - INFO - \n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.511\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.798\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.576\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.094\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.429\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.670\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.549\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.549\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.549\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.138\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.475\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.708\n",
      "\n",
      "2022-11-08 14:34:02,439 - mmdet - INFO - \n",
      "+------------+-------+\n",
      "| category   | AP    |\n",
      "+------------+-------+\n",
      "| pedestrian | 0.511 |\n",
      "+------------+-------+\n",
      "2022-11-08 14:34:02,466 - mmdet - INFO - Epoch(val) [4][823]\tbbox_mAP: 0.5110, bbox_mAP_50: 0.7980, bbox_mAP_75: 0.5760, bbox_mAP_s: 0.0940, bbox_mAP_m: 0.4290, bbox_mAP_l: 0.6700, bbox_mAP_copypaste: 0.511 0.798 0.576 0.094 0.429 0.670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=1.05s).\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmtrack.datasets import build_dataset\n",
    "from mmdet.apis import train_detector as train_model\n",
    "from mmdet.models import build_detector as build_model\n",
    "\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "model = build_model(cfg.model.detector)\n",
    "model.init_weights()\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "train_model(model, datasets, cfg, validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练ReID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集设置及模型设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "dataset_type = 'ReIDDataset'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadMultiImagesFromFile', to_float32=True),\n",
      "    dict(\n",
      "        type='SeqResize',\n",
      "        img_scale=(128, 256),\n",
      "        share_params=False,\n",
      "        keep_ratio=False,\n",
      "        bbox_clip_border=False,\n",
      "        override=False),\n",
      "    dict(\n",
      "        type='SeqRandomFlip',\n",
      "        share_params=False,\n",
      "        flip_ratio=0.5,\n",
      "        direction='horizontal'),\n",
      "    dict(\n",
      "        type='SeqNormalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='VideoCollect', keys=['img', 'gt_label']),\n",
      "    dict(type='ReIDFormatBundle')\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='Resize', img_scale=(128, 256), keep_ratio=False),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='ImageToTensor', keys=['img']),\n",
      "    dict(type='Collect', keys=['img'], meta_keys=[])\n",
      "]\n",
      "data_root = 'data/MOT17_tiny/'\n",
      "data = dict(\n",
      "    samples_per_gpu=1,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='ReIDDataset',\n",
      "        triplet_sampler=dict(num_ids=8, ins_per_id=4),\n",
      "        data_prefix='datasets/MOT17_tiny/reid/imgs',\n",
      "        ann_file='datasets/MOT17_tiny/reid/meta/train_9.txt',\n",
      "        pipeline=[\n",
      "            dict(type='LoadMultiImagesFromFile', to_float32=True),\n",
      "            dict(\n",
      "                type='SeqResize',\n",
      "                img_scale=(128, 256),\n",
      "                share_params=False,\n",
      "                keep_ratio=False,\n",
      "                bbox_clip_border=False,\n",
      "                override=False),\n",
      "            dict(\n",
      "                type='SeqRandomFlip',\n",
      "                share_params=False,\n",
      "                flip_ratio=0.5,\n",
      "                direction='horizontal'),\n",
      "            dict(\n",
      "                type='SeqNormalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='VideoCollect', keys=['img', 'gt_label']),\n",
      "            dict(type='ReIDFormatBundle')\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='ReIDDataset',\n",
      "        triplet_sampler=None,\n",
      "        data_prefix='datasets/MOT17_tiny/reid/imgs',\n",
      "        ann_file='datasets/MOT17_tiny/reid/meta/val_20.txt',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='Resize', img_scale=(128, 256), keep_ratio=False),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'], meta_keys=[])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='ReIDDataset',\n",
      "        triplet_sampler=None,\n",
      "        data_prefix='datasets/MOT17_tiny/reid/imgs',\n",
      "        ann_file='datasets/MOT17_tiny/reid/meta/val_20.txt',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='Resize', img_scale=(128, 256), keep_ratio=False),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'], meta_keys=[])\n",
      "        ]))\n",
      "evaluation = dict(interval=1, metric='mAP')\n",
      "optimizer = dict(type='SGD', lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "TRAIN_REID = True\n",
      "model = dict(\n",
      "    reid=dict(\n",
      "        type='BaseReID',\n",
      "        backbone=dict(\n",
      "            type='ResNet',\n",
      "            depth=50,\n",
      "            num_stages=4,\n",
      "            out_indices=(3, ),\n",
      "            style='pytorch'),\n",
      "        neck=dict(type='GlobalAveragePooling', kernel_size=(8, 4), stride=1),\n",
      "        head=dict(\n",
      "            type='LinearReIDHead',\n",
      "            num_fcs=1,\n",
      "            in_channels=2048,\n",
      "            fc_channels=1024,\n",
      "            out_channels=128,\n",
      "            num_classes=380,\n",
      "            loss=dict(type='CrossEntropyLoss', loss_weight=1.0),\n",
      "            loss_pairwise=dict(\n",
      "                type='TripletLoss', margin=0.3, loss_weight=1.0),\n",
      "            norm_cfg=dict(type='BN1d'),\n",
      "            act_cfg=dict(type='ReLU')),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth'\n",
      "        )))\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=200,\n",
      "    warmup_ratio=0.005,\n",
      "    step=[1])\n",
      "total_epochs = 2\n",
      "work_dir = './tutorial_exps/reid'\n",
      "seed = 0\n",
      "device = 'cuda'\n",
      "gpu_ids = [1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "from mmdet.apis import set_random_seed\n",
    "cfg = mmcv.Config.fromfile('./configs/reid/resnet50_b32x8_MOT17.py')\n",
    "cfg.data_root = 'data/MOT17_tiny/'\n",
    "cfg.data.test.ann_file = cfg.data.test.ann_file.replace('data/MOT17/','datasets/MOT17_tiny/')\n",
    "cfg.data.train.ann_file = 'datasets/MOT17_tiny/reid/meta/train_9.txt'\n",
    "cfg.data.val.ann_file = cfg.data.val.ann_file.replace('data/MOT17/','datasets/MOT17_tiny/')\n",
    "\n",
    "cfg.data.test.data_prefix = cfg.data.test.data_prefix.replace('data/MOT17/','datasets/MOT17_tiny/')\n",
    "cfg.data.train.data_prefix = cfg.data.train.data_prefix.replace('data/MOT17/','datasets/MOT17_tiny/')\n",
    "cfg.data.val.data_prefix = cfg.data.val.data_prefix.replace('data/MOT17/','datasets/MOT17_tiny/')\n",
    "\n",
    "# learning policy\n",
    "cfg.lr_config = dict(\n",
    "    policy='step',\n",
    "    warmup='linear',\n",
    "    warmup_iters=200,\n",
    "    warmup_ratio=1.0 / 200,\n",
    "    step=[1])\n",
    "cfg.total_epochs = 2\n",
    "\n",
    "cfg.work_dir = './tutorial_exps/reid'\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.device = \"cuda\"\n",
    "# cfg.gpu_ids = range(1)\n",
    "cfg.gpu_ids = [1]\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-28 08:56:43,296 - mmcv - INFO - initialize BaseReID with init_cfg {'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth'}\n",
      "2022-10-28 08:56:43,297 - mmcv - INFO - load model from: https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth\n",
      "2022-10-28 08:56:43,297 - mmcv - INFO - load checkpoint from http path: https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth\n",
      "2022-10-28 08:56:43,369 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: head.fc.weight, head.fc.bias\n",
      "\n",
      "missing keys in source state_dict: head.fcs.0.fc.weight, head.fcs.0.fc.bias, head.fcs.0.bn.weight, head.fcs.0.bn.bias, head.fcs.0.bn.running_mean, head.fcs.0.bn.running_var, head.fc_out.weight, head.fc_out.bias, head.bn.weight, head.bn.bias, head.bn.running_mean, head.bn.running_var, head.classifier.weight, head.classifier.bias\n",
      "\n",
      "2022-10-28 08:56:43,441 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
      "2022-10-28 08:56:43,443 - mmdet - INFO - Start running, host: root@0ea829b20e6b, work_dir: /workdir/tutorial_exps/reid\n",
      "2022-10-28 08:56:43,444 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-10-28 08:56:43,444 - mmdet - INFO - workflow: [('train', 1)], max: 2 epochs\n",
      "2022-10-28 08:56:43,445 - mmdet - INFO - Checkpoints will be saved to /workdir/tutorial_exps/reid by HardDiskBackend.\n",
      "2022-10-28 08:56:54,479 - mmdet - INFO - Epoch [1][50/1576]\tlr: 2.488e-02, eta: 0:11:20, time: 0.219, data_time: 0.051, memory: 2097, triplet_loss: 0.0910, ce_loss: 0.8236, top-1: 91.4375, loss: 0.9146\n",
      "2022-10-28 08:57:03,388 - mmdet - INFO - Epoch [1][100/1576]\tlr: 4.975e-02, eta: 0:10:06, time: 0.178, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0003, top-1: 100.0000, loss: 0.0003\n",
      "2022-10-28 08:57:12,283 - mmdet - INFO - Epoch [1][150/1576]\tlr: 7.463e-02, eta: 0:09:35, time: 0.178, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 08:57:21,257 - mmdet - INFO - Epoch [1][200/1576]\tlr: 9.950e-02, eta: 0:09:17, time: 0.179, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 08:57:30,180 - mmdet - INFO - Epoch [1][250/1576]\tlr: 1.000e-01, eta: 0:09:01, time: 0.178, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 08:57:39,077 - mmdet - INFO - Epoch [1][300/1576]\tlr: 1.000e-01, eta: 0:08:48, time: 0.178, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 08:57:47,992 - mmdet - INFO - Epoch [1][350/1576]\tlr: 1.000e-01, eta: 0:08:36, time: 0.178, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 08:57:56,920 - mmdet - INFO - Epoch [1][400/1576]\tlr: 1.000e-01, eta: 0:08:25, time: 0.179, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 08:58:05,835 - mmdet - INFO - Epoch [1][450/1576]\tlr: 1.000e-01, eta: 0:08:14, time: 0.178, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2022-10-28 08:58:14,840 - mmdet - INFO - Epoch [1][500/1576]\tlr: 1.000e-01, eta: 0:08:04, time: 0.180, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2022-10-28 08:58:23,760 - mmdet - INFO - Epoch [1][550/1576]\tlr: 1.000e-01, eta: 0:07:54, time: 0.178, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2022-10-28 08:58:32,687 - mmdet - INFO - Epoch [1][600/1576]\tlr: 1.000e-01, eta: 0:07:44, time: 0.179, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2022-10-28 08:58:41,594 - mmdet - INFO - Epoch [1][650/1576]\tlr: 1.000e-01, eta: 0:07:34, time: 0.178, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2022-10-28 08:58:51,628 - mmdet - INFO - Epoch [1][700/1576]\tlr: 1.000e-01, eta: 0:07:28, time: 0.200, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2022-10-28 08:59:04,891 - mmdet - INFO - Epoch [1][750/1576]\tlr: 1.000e-01, eta: 0:07:32, time: 0.265, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2022-10-28 08:59:18,153 - mmdet - INFO - Epoch [1][800/1576]\tlr: 1.000e-01, eta: 0:07:34, time: 0.265, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2022-10-28 08:59:31,571 - mmdet - INFO - Epoch [1][850/1576]\tlr: 1.000e-01, eta: 0:07:35, time: 0.268, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2022-10-28 08:59:43,428 - mmdet - INFO - Epoch [1][900/1576]\tlr: 1.000e-01, eta: 0:07:30, time: 0.237, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2022-10-28 08:59:53,378 - mmdet - INFO - Epoch [1][950/1576]\tlr: 1.000e-01, eta: 0:07:20, time: 0.199, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2022-10-28 09:00:03,622 - mmdet - INFO - Epoch [1][1000/1576]\tlr: 1.000e-01, eta: 0:07:10, time: 0.205, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2022-10-28 09:00:14,065 - mmdet - INFO - Epoch [1][1050/1576]\tlr: 1.000e-01, eta: 0:07:01, time: 0.209, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
      "2022-10-28 09:00:24,727 - mmdet - INFO - Epoch [1][1100/1576]\tlr: 1.000e-01, eta: 0:06:52, time: 0.213, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:00:35,535 - mmdet - INFO - Epoch [1][1150/1576]\tlr: 1.000e-01, eta: 0:06:43, time: 0.216, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:00:46,460 - mmdet - INFO - Epoch [1][1200/1576]\tlr: 1.000e-01, eta: 0:06:35, time: 0.219, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:00:57,482 - mmdet - INFO - Epoch [1][1250/1576]\tlr: 1.000e-01, eta: 0:06:26, time: 0.220, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:01:08,597 - mmdet - INFO - Epoch [1][1300/1576]\tlr: 1.000e-01, eta: 0:06:17, time: 0.222, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-28 09:01:19,807 - mmdet - INFO - Epoch [1][1350/1576]\tlr: 1.000e-01, eta: 0:06:08, time: 0.224, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:01:31,111 - mmdet - INFO - Epoch [1][1400/1576]\tlr: 1.000e-01, eta: 0:05:59, time: 0.226, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:01:42,500 - mmdet - INFO - Epoch [1][1450/1576]\tlr: 1.000e-01, eta: 0:05:50, time: 0.228, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:01:53,810 - mmdet - INFO - Epoch [1][1500/1576]\tlr: 1.000e-01, eta: 0:05:41, time: 0.226, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:02:05,089 - mmdet - INFO - Epoch [1][1550/1576]\tlr: 1.000e-01, eta: 0:05:32, time: 0.225, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:02:10,933 - mmdet - INFO - Saving checkpoint at 1 epochs\n",
      "2022-10-28 09:02:23,948 - mmdet - INFO - Epoch [2][50/1576]\tlr: 1.000e-02, eta: 0:05:13, time: 0.250, data_time: 0.047, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:02:35,091 - mmdet - INFO - Epoch [2][100/1576]\tlr: 1.000e-02, eta: 0:05:04, time: 0.223, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:02:51,344 - mmdet - INFO - Epoch [2][150/1576]\tlr: 1.000e-02, eta: 0:04:58, time: 0.324, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:03:03,967 - mmdet - INFO - Epoch [2][200/1576]\tlr: 1.000e-02, eta: 0:04:49, time: 0.253, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:03:15,527 - mmdet - INFO - Epoch [2][250/1576]\tlr: 1.000e-02, eta: 0:04:40, time: 0.231, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:03:27,161 - mmdet - INFO - Epoch [2][300/1576]\tlr: 1.000e-02, eta: 0:04:30, time: 0.233, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:03:40,978 - mmdet - INFO - Epoch [2][350/1576]\tlr: 1.000e-02, eta: 0:04:21, time: 0.275, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:03:54,460 - mmdet - INFO - Epoch [2][400/1576]\tlr: 1.000e-02, eta: 0:04:12, time: 0.270, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:04:06,334 - mmdet - INFO - Epoch [2][450/1576]\tlr: 1.000e-02, eta: 0:04:02, time: 0.238, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:04:18,298 - mmdet - INFO - Epoch [2][500/1576]\tlr: 1.000e-02, eta: 0:03:52, time: 0.239, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:04:30,231 - mmdet - INFO - Epoch [2][550/1576]\tlr: 1.000e-02, eta: 0:03:42, time: 0.239, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:04:42,191 - mmdet - INFO - Epoch [2][600/1576]\tlr: 1.000e-02, eta: 0:03:31, time: 0.239, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:04:54,218 - mmdet - INFO - Epoch [2][650/1576]\tlr: 1.000e-02, eta: 0:03:21, time: 0.240, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:05:12,285 - mmdet - INFO - Epoch [2][700/1576]\tlr: 1.000e-02, eta: 0:03:13, time: 0.360, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:05:25,217 - mmdet - INFO - Epoch [2][750/1576]\tlr: 1.000e-02, eta: 0:03:02, time: 0.260, data_time: 0.006, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:05:37,340 - mmdet - INFO - Epoch [2][800/1576]\tlr: 1.000e-02, eta: 0:02:52, time: 0.242, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:05:49,479 - mmdet - INFO - Epoch [2][850/1576]\tlr: 1.000e-02, eta: 0:02:41, time: 0.243, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:06:01,533 - mmdet - INFO - Epoch [2][900/1576]\tlr: 1.000e-02, eta: 0:02:30, time: 0.241, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:06:13,618 - mmdet - INFO - Epoch [2][950/1576]\tlr: 1.000e-02, eta: 0:02:19, time: 0.242, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:06:25,628 - mmdet - INFO - Epoch [2][1000/1576]\tlr: 1.000e-02, eta: 0:02:08, time: 0.240, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:06:37,621 - mmdet - INFO - Epoch [2][1050/1576]\tlr: 1.000e-02, eta: 0:01:57, time: 0.240, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:06:49,633 - mmdet - INFO - Epoch [2][1100/1576]\tlr: 1.000e-02, eta: 0:01:46, time: 0.240, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:07:01,745 - mmdet - INFO - Epoch [2][1150/1576]\tlr: 1.000e-02, eta: 0:01:35, time: 0.242, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:07:13,746 - mmdet - INFO - Epoch [2][1200/1576]\tlr: 1.000e-02, eta: 0:01:24, time: 0.240, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:07:25,695 - mmdet - INFO - Epoch [2][1250/1576]\tlr: 1.000e-02, eta: 0:01:13, time: 0.239, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:07:37,773 - mmdet - INFO - Epoch [2][1300/1576]\tlr: 1.000e-02, eta: 0:01:02, time: 0.242, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:07:49,816 - mmdet - INFO - Epoch [2][1350/1576]\tlr: 1.000e-02, eta: 0:00:50, time: 0.241, data_time: 0.004, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:08:01,929 - mmdet - INFO - Epoch [2][1400/1576]\tlr: 1.000e-02, eta: 0:00:39, time: 0.242, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:08:14,109 - mmdet - INFO - Epoch [2][1450/1576]\tlr: 1.000e-02, eta: 0:00:28, time: 0.244, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:08:26,278 - mmdet - INFO - Epoch [2][1500/1576]\tlr: 1.000e-02, eta: 0:00:17, time: 0.243, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:08:38,435 - mmdet - INFO - Epoch [2][1550/1576]\tlr: 1.000e-02, eta: 0:00:05, time: 0.243, data_time: 0.005, memory: 2097, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
      "2022-10-28 09:08:44,761 - mmdet - INFO - Saving checkpoint at 2 epochs\n"
     ]
    }
   ],
   "source": [
    "from mmtrack.datasets import build_dataset\n",
    "from mmdet.apis import train_detector as train_model\n",
    "from mmtrack.models import build_reid as build_model\n",
    "\n",
    "\n",
    "model = build_model(cfg.model.reid)\n",
    "model.init_weights()\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "\n",
    "train_model(model, datasets, cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 验证模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    detector=dict(\n",
      "        type='FasterRCNN',\n",
      "        backbone=dict(\n",
      "            type='ResNet',\n",
      "            depth=50,\n",
      "            num_stages=4,\n",
      "            out_indices=(0, 1, 2, 3),\n",
      "            frozen_stages=1,\n",
      "            norm_cfg=dict(type='BN', requires_grad=True),\n",
      "            norm_eval=True,\n",
      "            style='pytorch',\n",
      "            init_cfg=dict(\n",
      "                type='Pretrained', checkpoint='torchvision://resnet50')),\n",
      "        neck=dict(\n",
      "            type='FPN',\n",
      "            in_channels=[256, 512, 1024, 2048],\n",
      "            out_channels=256,\n",
      "            num_outs=5),\n",
      "        rpn_head=dict(\n",
      "            type='RPNHead',\n",
      "            in_channels=256,\n",
      "            feat_channels=256,\n",
      "            anchor_generator=dict(\n",
      "                type='AnchorGenerator',\n",
      "                scales=[8],\n",
      "                ratios=[0.5, 1.0, 2.0],\n",
      "                strides=[4, 8, 16, 32, 64]),\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[1.0, 1.0, 1.0, 1.0],\n",
      "                clip_border=False),\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "            loss_bbox=dict(\n",
      "                type='SmoothL1Loss', beta=0.1111111111111111,\n",
      "                loss_weight=1.0)),\n",
      "        roi_head=dict(\n",
      "            type='StandardRoIHead',\n",
      "            bbox_roi_extractor=dict(\n",
      "                type='SingleRoIExtractor',\n",
      "                roi_layer=dict(\n",
      "                    type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "                out_channels=256,\n",
      "                featmap_strides=[4, 8, 16, 32]),\n",
      "            bbox_head=dict(\n",
      "                type='Shared2FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=1,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.1, 0.1, 0.2, 0.2],\n",
      "                    clip_border=False),\n",
      "                reg_class_agnostic=False,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='SmoothL1Loss', loss_weight=1.0))),\n",
      "        train_cfg=dict(\n",
      "            rpn=dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.7,\n",
      "                    neg_iou_thr=0.3,\n",
      "                    min_pos_iou=0.3,\n",
      "                    match_low_quality=True,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=256,\n",
      "                    pos_fraction=0.5,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=False),\n",
      "                allowed_border=-1,\n",
      "                pos_weight=-1,\n",
      "                debug=False),\n",
      "            rpn_proposal=dict(\n",
      "                nms_pre=2000,\n",
      "                max_per_img=1000,\n",
      "                nms=dict(type='nms', iou_threshold=0.7),\n",
      "                min_bbox_size=0),\n",
      "            rcnn=dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    min_pos_iou=0.5,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False)),\n",
      "        test_cfg=dict(\n",
      "            rpn=dict(\n",
      "                nms_pre=1000,\n",
      "                max_per_img=1000,\n",
      "                nms=dict(type='nms', iou_threshold=0.7),\n",
      "                min_bbox_size=0),\n",
      "            rcnn=dict(\n",
      "                score_thr=0.05,\n",
      "                nms=dict(type='nms', iou_threshold=0.5),\n",
      "                max_per_img=100)),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint='./tutorial_exps/detector/epoch_4.pth')),\n",
      "    type='DeepSORT',\n",
      "    motion=dict(type='KalmanFilter', center_only=False),\n",
      "    reid=dict(\n",
      "        type='BaseReID',\n",
      "        backbone=dict(\n",
      "            type='ResNet',\n",
      "            depth=50,\n",
      "            num_stages=4,\n",
      "            out_indices=(3, ),\n",
      "            style='pytorch'),\n",
      "        neck=dict(type='GlobalAveragePooling', kernel_size=(8, 4), stride=1),\n",
      "        head=dict(\n",
      "            type='LinearReIDHead',\n",
      "            num_fcs=1,\n",
      "            in_channels=2048,\n",
      "            fc_channels=1024,\n",
      "            out_channels=128,\n",
      "            num_classes=380,\n",
      "            loss=dict(type='CrossEntropyLoss', loss_weight=1.0),\n",
      "            loss_pairwise=dict(\n",
      "                type='TripletLoss', margin=0.3, loss_weight=1.0),\n",
      "            norm_cfg=dict(type='BN1d'),\n",
      "            act_cfg=dict(type='ReLU')),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained', checkpoint='./tutorial_exps/reid/epoch_2.pth')),\n",
      "    tracker=dict(\n",
      "        type='SortTracker',\n",
      "        obj_score_thr=0.5,\n",
      "        reid=dict(\n",
      "            num_samples=10,\n",
      "            img_scale=(256, 128),\n",
      "            img_norm_cfg=None,\n",
      "            match_score_thr=2.0),\n",
      "        match_iou_thr=0.5,\n",
      "        momentums=None,\n",
      "        num_tentatives=2,\n",
      "        num_frames_retain=100))\n",
      "dataset_type = 'MOTChallengeDataset'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadMultiImagesFromFile', to_float32=True),\n",
      "    dict(type='SeqLoadAnnotations', with_bbox=True, with_track=True),\n",
      "    dict(\n",
      "        type='SeqResize',\n",
      "        img_scale=(1088, 1088),\n",
      "        share_params=True,\n",
      "        ratio_range=(0.8, 1.2),\n",
      "        keep_ratio=True,\n",
      "        bbox_clip_border=False),\n",
      "    dict(type='SeqPhotoMetricDistortion', share_params=True),\n",
      "    dict(\n",
      "        type='SeqRandomCrop',\n",
      "        share_params=False,\n",
      "        crop_size=(1088, 1088),\n",
      "        bbox_clip_border=False),\n",
      "    dict(type='SeqRandomFlip', share_params=True, flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='SeqNormalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='SeqPad', size_divisor=32),\n",
      "    dict(type='MatchInstances', skip_nomatch=True),\n",
      "    dict(\n",
      "        type='VideoCollect',\n",
      "        keys=[\n",
      "            'img', 'gt_bboxes', 'gt_labels', 'gt_match_indices',\n",
      "            'gt_instance_ids'\n",
      "        ]),\n",
      "    dict(type='SeqDefaultFormatBundle', ref_prefix='ref')\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1088, 1088),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='VideoCollect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data_root = 'data/MOT17_tiny/'\n",
      "data = dict(\n",
      "    samples_per_gpu=2,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='MOTChallengeDataset',\n",
      "        visibility_thr=-1,\n",
      "        ann_file='datasets/MOT17_tiny/annotations/half-val_cocoformat.json',\n",
      "        img_prefix='datasets/MOT17_tiny/train',\n",
      "        ref_img_sampler=dict(\n",
      "            num_ref_imgs=1,\n",
      "            frame_range=10,\n",
      "            filter_key_img=True,\n",
      "            method='uniform'),\n",
      "        pipeline=[\n",
      "            dict(type='LoadMultiImagesFromFile', to_float32=True),\n",
      "            dict(type='SeqLoadAnnotations', with_bbox=True, with_track=True),\n",
      "            dict(\n",
      "                type='SeqResize',\n",
      "                img_scale=(1088, 1088),\n",
      "                share_params=True,\n",
      "                ratio_range=(0.8, 1.2),\n",
      "                keep_ratio=True,\n",
      "                bbox_clip_border=False),\n",
      "            dict(type='SeqPhotoMetricDistortion', share_params=True),\n",
      "            dict(\n",
      "                type='SeqRandomCrop',\n",
      "                share_params=False,\n",
      "                crop_size=(1088, 1088),\n",
      "                bbox_clip_border=False),\n",
      "            dict(type='SeqRandomFlip', share_params=True, flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='SeqNormalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='SeqPad', size_divisor=32),\n",
      "            dict(type='MatchInstances', skip_nomatch=True),\n",
      "            dict(\n",
      "                type='VideoCollect',\n",
      "                keys=[\n",
      "                    'img', 'gt_bboxes', 'gt_labels', 'gt_match_indices',\n",
      "                    'gt_instance_ids'\n",
      "                ]),\n",
      "            dict(type='SeqDefaultFormatBundle', ref_prefix='ref')\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='MOTChallengeDataset',\n",
      "        ann_file='datasets/MOT17_tiny/annotations/half-val_cocoformat.json',\n",
      "        img_prefix='datasets/MOT17_tiny/train',\n",
      "        ref_img_sampler=None,\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1088, 1088),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='VideoCollect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='MOTChallengeDataset',\n",
      "        ann_file='datasets/MOT17_tiny/annotations/half-val_cocoformat.json',\n",
      "        img_prefix='datasets/MOT17_tiny/train',\n",
      "        ref_img_sampler=None,\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1088, 1088),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='VideoCollect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        test_mode=True))\n",
      "optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=100,\n",
      "    warmup_ratio=0.01,\n",
      "    step=[3])\n",
      "total_epochs = 4\n",
      "evaluation = dict(metric=['bbox', 'track'], interval=1)\n",
      "search_metrics = ['MOTA', 'IDF1', 'FN', 'FP', 'IDs', 'MT', 'ML']\n",
      "work_dir = './tutorial_exps'\n",
      "seed = 0\n",
      "device = 'cuda'\n",
      "gpu_ids = [0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "from mmdet.apis import set_random_seed\n",
    "cfg = mmcv.Config.fromfile('./configs/mot/deepsort/deepsort_faster-rcnn_fpn_4e_mot17-private-half.py')\n",
    "cfg.data_root = 'data/MOT17_tiny/'\n",
    "cfg.data.test.ann_file = cfg.data.test.ann_file.replace('data/MOT17/','datasets/MOT17_tiny/')\n",
    "cfg.data.train.ann_file = cfg.data.test.ann_file.replace('data/MOT17/','datasets/MOT17_tiny/')\n",
    "cfg.data.val.ann_file = cfg.data.val.ann_file.replace('data/MOT17/','datasets/MOT17_tiny/')\n",
    "\n",
    "cfg.data.test.img_prefix = cfg.data.test.img_prefix.replace('data/MOT17/','datasets/MOT17_tiny/')\n",
    "cfg.data.train.img_prefix = cfg.data.train.img_prefix.replace('data/MOT17/','datasets/MOT17_tiny/')\n",
    "cfg.data.val.img_prefix = cfg.data.val.img_prefix.replace('data/MOT17/','datasets/MOT17_tiny/')\n",
    "\n",
    "cfg.model.detector.init_cfg.checkpoint = './tutorial_exps/detector/epoch_4.pth'\n",
    "cfg.model.reid.init_cfg.checkpoint = './tutorial_exps/reid/epoch_2.pth'\n",
    "\n",
    "cfg.work_dir = './tutorial_exps'\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.device = 'cuda'\n",
    "# cfg.gpu_ids = range(1)\n",
    "cfg.gpu_ids = [0]\n",
    "cfg.data.test.test_mode = True\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.12s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-28 10:42:48,070 - mmtrack - INFO - initialize FasterRCNN with init_cfg {'type': 'Pretrained', 'checkpoint': './tutorial_exps/detector/epoch_4.pth'}\n",
      "2022-10-28 10:42:48,071 - mmcv - INFO - load model from: ./tutorial_exps/detector/epoch_4.pth\n",
      "2022-10-28 10:42:48,072 - mmcv - INFO - load checkpoint from local path: ./tutorial_exps/detector/epoch_4.pth\n",
      "2022-10-28 10:42:49,852 - mmtrack - INFO - initialize BaseReID with init_cfg {'type': 'Pretrained', 'checkpoint': './tutorial_exps/reid/epoch_2.pth'}\n",
      "2022-10-28 10:42:49,853 - mmcv - INFO - load model from: ./tutorial_exps/reid/epoch_2.pth\n",
      "2022-10-28 10:42:49,854 - mmcv - INFO - load checkpoint from local path: ./tutorial_exps/reid/epoch_2.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The model doesn't have classes\n",
      "[                                 ] 1/823, 1.9 task/s, elapsed: 1s, ETA:   430s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448224956/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 823/823, 8.4 task/s, elapsed: 98s, ETA:     0sEvaluate CLEAR MOT results.\n",
      "\n",
      "Eval Config:\n",
      "USE_PARALLEL         : False                         \n",
      "NUM_PARALLEL_CORES   : 8                             \n",
      "BREAK_ON_ERROR       : True                          \n",
      "RETURN_ON_ERROR      : False                         \n",
      "LOG_ON_ERROR         : /opt/conda/lib/python3.7/site-packages/error_log.txt\n",
      "PRINT_RESULTS        : True                          \n",
      "PRINT_ONLY_COMBINED  : False                         \n",
      "PRINT_CONFIG         : True                          \n",
      "TIME_PROGRESS        : True                          \n",
      "DISPLAY_LESS_PROGRESS : True                          \n",
      "OUTPUT_SUMMARY       : True                          \n",
      "OUTPUT_EMPTY_CLASSES : True                          \n",
      "OUTPUT_DETAILED      : True                          \n",
      "PLOT_CURVES          : True                          \n",
      "\n",
      "MotChallenge2DBox Config:\n",
      "GT_FOLDER            : /tmp/tmpni87iqvn              \n",
      "TRACKERS_FOLDER      : /tmp/tmp10xfn7uq              \n",
      "OUTPUT_FOLDER        : None                          \n",
      "TRACKERS_TO_EVAL     : ['track']                     \n",
      "CLASSES_TO_EVAL      : ['pedestrian']                \n",
      "BENCHMARK            : MOT17                         \n",
      "SPLIT_TO_EVAL        : train                         \n",
      "INPUT_AS_ZIP         : False                         \n",
      "PRINT_CONFIG         : True                          \n",
      "DO_PREPROC           : True                          \n",
      "TRACKER_SUB_FOLDER   :                               \n",
      "OUTPUT_SUB_FOLDER    :                               \n",
      "TRACKER_DISPLAY_NAMES : None                          \n",
      "SEQMAP_FOLDER        : None                          \n",
      "SEQMAP_FILE          : /tmp/tmp10xfn7uq/videoseq.txt \n",
      "SEQ_INFO             : None                          \n",
      "GT_LOC_FORMAT        : {gt_folder}/{seq}/gt/gt_half-val.txt\n",
      "SKIP_SPLIT_FOL       : True                          \n",
      "\n",
      "Evaluating 1 tracker(s) on 2 sequence(s) for 1 class(es) on MotChallenge2DBox dataset using the following metrics: HOTA, Count\n",
      "\n",
      "\n",
      "Evaluating track\n",
      "\n",
      "1 eval_sequence(MOT17-02-FRCNN, track)                                   0.4545 sec\n",
      "2 eval_sequence(MOT17-04-FRCNN, track)                                   1.1531 sec\n",
      "\n",
      "All sequences for track finished in 1.61 seconds\n",
      "\n",
      "HOTA: track-pedestrian             HOTA      DetA      AssA      DetRe     DetPr     AssRe     AssPr     LocA      RHOTA     HOTA(0)   LocA(0)   HOTALocA(0)\n",
      "MOT17-02-FRCNN                     26.647    39.682    18.895    47.365    62.188    21.876    53.096    79.43     29.385    34.006    69.061    23.485    \n",
      "MOT17-04-FRCNN                     51.256    66.776    40.813    71.592    81.622    46.407    59.338    84.782    53.434    60.616    81.562    49.44     \n",
      "COMBINED                           44.982    58.179    36.364    64.564    76.532    41.458    58.247    83.579    47.746    53.94     78.523    42.355    \n",
      "\n",
      "Count: track-pedestrian            Dets      GT_Dets   IDs       GT_IDs    \n",
      "MOT17-02-FRCNN                     7525      9880      423       53        \n",
      "MOT17-04-FRCNN                     21207     24178     172       69        \n",
      "COMBINED                           28732     34058     595       122       \n",
      "                IDF1   IDP   IDR  Rcll  Prcn  GT MT PT ML   FP   FN  IDs   FM  MOTA  MOTP IDt IDa IDm      HOTA\n",
      "MOT17-04-FRCNN 54.7% 58.5% 51.3% 84.7% 96.6%  69 50 17  2  722 3693 1384  330 76.0% 0.174 454  81  13  0.512559\n",
      "MOT17-02-FRCNN 29.6% 34.2% 26.1% 56.6% 74.3%  53 12 33  8 1937 4292 1008  375 26.8% 0.222 393 204   6  0.266472\n",
      "OVERALL        47.7% 52.2% 44.0% 76.6% 90.7% 122 62 50 10 2659 7985 2392  705 61.7% 0.184 847 285  19  0.449819\n",
      "{'IDF1': 0.477, 'IDP': 0.522, 'IDR': 0.44, 'Rcll': 0.766, 'Prcn': 0.907, 'GT': 122, 'MT': 62, 'PT': 50, 'ML': 10, 'FP': 2659, 'FN': 7985, 'IDs': 2392, 'FM': 705, 'MOTA': 0.617, 'MOTP': 0.184, 'IDt': 847, 'IDa': 285, 'IDm': 19, 'HOTA': 0.45}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mmtrack.datasets import build_dataloader\n",
    "from mmtrack.apis import init_model\n",
    "from mmcv.parallel import MMDataParallel\n",
    "from mmtrack.apis import single_gpu_test\n",
    "from mmtrack.datasets import build_dataset\n",
    "\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "data_loader = build_dataloader(\n",
    "    dataset,\n",
    "    samples_per_gpu=1,\n",
    "    workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "    dist=False,\n",
    "    shuffle=False)\n",
    "\n",
    "# build the model and load checkpoint\n",
    "model = init_model(cfg)\n",
    "\n",
    "model = MMDataParallel(model, device_ids=cfg.gpu_ids)\n",
    "outputs = single_gpu_test(model, data_loader)\n",
    "\n",
    "eval_kwargs = cfg.get('evaluation', {}).copy()\n",
    "# hard-code way to remove EvalHook args\n",
    "eval_hook_args = [\n",
    "    'interval', 'tmpdir', 'start', 'gpu_collect', 'save_best',\n",
    "    'rule', 'by_epoch'\n",
    "]\n",
    "for key in eval_hook_args:\n",
    "    eval_kwargs.pop(key, None)\n",
    "eval_kwargs.update(dict(metric=['track']))\n",
    "metric = dataset.evaluate(outputs, **eval_kwargs)\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:47:20,573 - mmcv - INFO - initialize FasterRCNN with init_cfg {'type': 'Pretrained', 'checkpoint': './tutorial_exps/detector/epoch_4.pth'}\n",
      "2022-11-08 14:47:20,573 - mmcv - INFO - load model from: ./tutorial_exps/detector/epoch_4.pth\n",
      "2022-11-08 14:47:20,574 - mmcv - INFO - load checkpoint from local path: ./tutorial_exps/detector/epoch_4.pth\n",
      "2022-11-08 14:47:20,775 - mmcv - INFO - initialize BaseReID with init_cfg {'type': 'Pretrained', 'checkpoint': './tutorial_exps/reid/epoch_2.pth'}\n",
      "2022-11-08 14:47:20,775 - mmcv - INFO - load model from: ./tutorial_exps/reid/epoch_2.pth\n",
      "2022-11-08 14:47:20,776 - mmcv - INFO - load checkpoint from local path: ./tutorial_exps/reid/epoch_2.pth\n",
      "2022-11-08 14:47:22,703 - mmcv - INFO - \n",
      "detector.backbone.conv1.weight - torch.Size([64, 3, 7, 7]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,704 - mmcv - INFO - \n",
      "detector.backbone.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,704 - mmcv - INFO - \n",
      "detector.backbone.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,705 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,705 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,706 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,706 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,707 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,707 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,707 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,708 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,708 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,709 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,709 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.downsample.1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,709 - mmcv - INFO - \n",
      "detector.backbone.layer1.0.downsample.1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,710 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,710 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,711 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,711 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,712 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,712 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,712 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,713 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,713 - mmcv - INFO - \n",
      "detector.backbone.layer1.1.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,714 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,714 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,715 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,715 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,715 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,716 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,716 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,717 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,717 - mmcv - INFO - \n",
      "detector.backbone.layer1.2.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,717 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,718 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,718 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,719 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,719 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,719 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,720 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,720 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,721 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,721 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,721 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.downsample.1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:47:22,722 - mmcv - INFO - \n",
      "detector.backbone.layer2.0.downsample.1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,722 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,723 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,723 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,724 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,724 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,724 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,725 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,731 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,732 - mmcv - INFO - \n",
      "detector.backbone.layer2.1.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,733 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,733 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,733 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,734 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,734 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,735 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,735 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,736 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,736 - mmcv - INFO - \n",
      "detector.backbone.layer2.2.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,736 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,737 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,737 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,738 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,738 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,739 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,739 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,739 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,740 - mmcv - INFO - \n",
      "detector.backbone.layer2.3.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,740 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,741 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,741 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,742 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,742 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,742 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,743 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,743 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,744 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,744 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,744 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.downsample.1.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,745 - mmcv - INFO - \n",
      "detector.backbone.layer3.0.downsample.1.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,745 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,746 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,746 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,746 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,747 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,747 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,748 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,748 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:47:22,749 - mmcv - INFO - \n",
      "detector.backbone.layer3.1.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,749 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,750 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,750 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,751 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,751 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,751 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,752 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,752 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,753 - mmcv - INFO - \n",
      "detector.backbone.layer3.2.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,753 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,759 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,759 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,759 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,760 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,760 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,761 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,761 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,761 - mmcv - INFO - \n",
      "detector.backbone.layer3.3.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,762 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,762 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,763 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,763 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,764 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,764 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,764 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,765 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,765 - mmcv - INFO - \n",
      "detector.backbone.layer3.4.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,766 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,766 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,766 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,767 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,767 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,768 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,768 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,772 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,773 - mmcv - INFO - \n",
      "detector.backbone.layer3.5.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,774 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,774 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,775 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,775 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,775 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,776 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,776 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,777 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,777 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,777 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,778 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.downsample.1.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:47:22,778 - mmcv - INFO - \n",
      "detector.backbone.layer4.0.downsample.1.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,779 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,779 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,780 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,780 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,780 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,781 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,784 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,784 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,785 - mmcv - INFO - \n",
      "detector.backbone.layer4.1.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,785 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,785 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,786 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,786 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,787 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,787 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,787 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,788 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,788 - mmcv - INFO - \n",
      "detector.backbone.layer4.2.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,789 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.0.conv.weight - torch.Size([256, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,789 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.0.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,790 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.1.conv.weight - torch.Size([256, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,790 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.1.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,790 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.2.conv.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,791 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.2.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,791 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.3.conv.weight - torch.Size([256, 2048, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,792 - mmcv - INFO - \n",
      "detector.neck.lateral_convs.3.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,792 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,793 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.0.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,793 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,793 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.1.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,794 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,794 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.2.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,795 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,795 - mmcv - INFO - \n",
      "detector.neck.fpn_convs.3.conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,795 - mmcv - INFO - \n",
      "detector.rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,796 - mmcv - INFO - \n",
      "detector.rpn_head.rpn_conv.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,796 - mmcv - INFO - \n",
      "detector.rpn_head.rpn_cls.weight - torch.Size([3, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,797 - mmcv - INFO - \n",
      "detector.rpn_head.rpn_cls.bias - torch.Size([3]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,797 - mmcv - INFO - \n",
      "detector.rpn_head.rpn_reg.weight - torch.Size([12, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,797 - mmcv - INFO - \n",
      "detector.rpn_head.rpn_reg.bias - torch.Size([12]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,798 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.fc_cls.weight - torch.Size([2, 1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,798 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.fc_cls.bias - torch.Size([2]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,799 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.fc_reg.weight - torch.Size([4, 1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,799 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.fc_reg.bias - torch.Size([4]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,800 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,800 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.shared_fcs.0.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,800 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.shared_fcs.1.weight - torch.Size([1024, 1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:47:22,801 - mmcv - INFO - \n",
      "detector.roi_head.bbox_head.shared_fcs.1.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/detector/epoch_4.pth \n",
      " \n",
      "2022-11-08 14:47:22,801 - mmcv - INFO - \n",
      "reid.backbone.conv1.weight - torch.Size([64, 3, 7, 7]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,802 - mmcv - INFO - \n",
      "reid.backbone.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,802 - mmcv - INFO - \n",
      "reid.backbone.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,802 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,803 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,803 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,804 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,804 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,805 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,805 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,805 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,806 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,806 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,807 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.downsample.1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,807 - mmcv - INFO - \n",
      "reid.backbone.layer1.0.downsample.1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,807 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,808 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,808 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,809 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,809 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,810 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,810 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,810 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,811 - mmcv - INFO - \n",
      "reid.backbone.layer1.1.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,811 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,812 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.bn1.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,812 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.bn1.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,812 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,813 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.bn2.weight - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,813 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.bn2.bias - torch.Size([64]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,814 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,814 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.bn3.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,814 - mmcv - INFO - \n",
      "reid.backbone.layer1.2.bn3.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,815 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,815 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,816 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,816 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,817 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,820 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,820 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,821 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,821 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,822 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,822 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.downsample.1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,822 - mmcv - INFO - \n",
      "reid.backbone.layer2.0.downsample.1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,823 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,823 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,824 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,824 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,825 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:47:22,825 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,825 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,826 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,826 - mmcv - INFO - \n",
      "reid.backbone.layer2.1.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,827 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,827 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,827 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,828 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,828 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,829 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,829 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,829 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,830 - mmcv - INFO - \n",
      "reid.backbone.layer2.2.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,830 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,831 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.bn1.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,831 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.bn1.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,832 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,832 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.bn2.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,832 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.bn2.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,833 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,833 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.bn3.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,834 - mmcv - INFO - \n",
      "reid.backbone.layer2.3.bn3.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,834 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,834 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,835 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,835 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,836 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,836 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,836 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,837 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,837 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,838 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,838 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.downsample.1.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,839 - mmcv - INFO - \n",
      "reid.backbone.layer3.0.downsample.1.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,839 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,839 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,840 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,840 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,841 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,841 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,848 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,856 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,856 - mmcv - INFO - \n",
      "reid.backbone.layer3.1.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,856 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,857 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,857 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,858 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,858 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,858 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,859 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,859 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:47:22,860 - mmcv - INFO - \n",
      "reid.backbone.layer3.2.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,860 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,861 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,861 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,861 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,862 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,862 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,863 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,863 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,863 - mmcv - INFO - \n",
      "reid.backbone.layer3.3.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,864 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,864 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,865 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,865 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,866 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,866 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,867 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,867 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,868 - mmcv - INFO - \n",
      "reid.backbone.layer3.4.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,868 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,869 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.bn1.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,869 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.bn1.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,870 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,870 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.bn2.weight - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,870 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.bn2.bias - torch.Size([256]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,871 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,871 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.bn3.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,872 - mmcv - INFO - \n",
      "reid.backbone.layer3.5.bn3.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,872 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,873 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,873 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,874 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,874 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,875 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,875 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,876 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,876 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,877 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,877 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.downsample.1.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,877 - mmcv - INFO - \n",
      "reid.backbone.layer4.0.downsample.1.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,878 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,878 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,879 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,879 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,880 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,880 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,881 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,881 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,882 - mmcv - INFO - \n",
      "reid.backbone.layer4.1.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,882 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,883 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.bn1.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 14:47:22,883 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.bn1.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,884 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,884 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.bn2.weight - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,885 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.bn2.bias - torch.Size([512]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,885 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,886 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.bn3.weight - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,886 - mmcv - INFO - \n",
      "reid.backbone.layer4.2.bn3.bias - torch.Size([2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,887 - mmcv - INFO - \n",
      "reid.head.fcs.0.fc.weight - torch.Size([1024, 2048]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,887 - mmcv - INFO - \n",
      "reid.head.fcs.0.fc.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,887 - mmcv - INFO - \n",
      "reid.head.fcs.0.bn.weight - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,888 - mmcv - INFO - \n",
      "reid.head.fcs.0.bn.bias - torch.Size([1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,888 - mmcv - INFO - \n",
      "reid.head.fc_out.weight - torch.Size([128, 1024]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,889 - mmcv - INFO - \n",
      "reid.head.fc_out.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,889 - mmcv - INFO - \n",
      "reid.head.bn.weight - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,890 - mmcv - INFO - \n",
      "reid.head.bn.bias - torch.Size([128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,890 - mmcv - INFO - \n",
      "reid.head.classifier.weight - torch.Size([380, 128]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n",
      "2022-11-08 14:47:22,891 - mmcv - INFO - \n",
      "reid.head.classifier.bias - torch.Size([380]): \n",
      "PretrainedInit: load from ./tutorial_exps/reid/epoch_2.pth \n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The model doesn't have classes\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 8/8, 5.9 task/s, elapsed: 1s, ETA:     0s\n",
      " making the output video at ./demo/mot.mp4 with a FPS of 3.0\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 8/8, 36.5 task/s, elapsed: 0s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "# run mot demo\n",
    "import mmcv\n",
    "import tempfile\n",
    "from mmtrack.apis import inference_mot, init_model\n",
    "cfg = mmcv.Config.fromfile('./configs/mot/deepsort/deepsort_faster-rcnn_fpn_4e_mot17-private-half.py')\n",
    "cfg.model.detector.init_cfg.checkpoint = './tutorial_exps/detector/epoch_4.pth'\n",
    "cfg.model.reid.init_cfg.checkpoint = './tutorial_exps/reid/epoch_2.pth'\n",
    "\n",
    "input_video = './demo/demo.mp4'\n",
    "imgs = mmcv.VideoReader(input_video)\n",
    "# build the model from a config file\n",
    "mot_model = init_model(cfg)\n",
    "prog_bar = mmcv.ProgressBar(len(imgs))\n",
    "out_dir = tempfile.TemporaryDirectory()\n",
    "out_path = out_dir.name\n",
    "# test and show/save the images\n",
    "for i, img in enumerate(imgs):\n",
    "    result = inference_mot(mot_model, img, frame_id=i)\n",
    "    mot_model.show_result(\n",
    "            img,\n",
    "            result,\n",
    "            show=False,\n",
    "            wait_time=int(1000. / imgs.fps),\n",
    "            out_file=f'{out_path}/{i:06d}.jpg')\n",
    "    prog_bar.update()\n",
    "\n",
    "output = './demo/mot.mp4'\n",
    "print(f'\\n making the output video at {output} with a FPS of {imgs.fps}')\n",
    "mmcv.frames2video(out_path, output, fps=imgs.fps, fourcc='mp4v')\n",
    "out_dir.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "326.989px",
    "width": "211.989px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
